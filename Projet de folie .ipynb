{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PRE TREATMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing all our **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "## Actually used\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import warnings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from IPython.display import Image  \n",
    "from sklearn import tree\n",
    "import pydotplus\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files (x86)\\Graphviz2.38\\bin'\n",
    "\n",
    "## Actually not used \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from mpl_toolkits import mplot3d\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "DATA_PATH = os.path.join(\"./data\")\n",
    "DATA_NAME_CSV = \"CyberTroll.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of our data and transformation into DataFrame with **pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the .csv file into a DataFrame\n",
    "def load_data(data_path=DATA_PATH,data_name_csv=DATA_NAME_CSV):\n",
    "        # Path to file .csv\n",
    "        csv_path = os.path.join(data_path,data_name_csv)\n",
    "        # Object DATA_FRAME\n",
    "        return pd.read_csv(csv_path)\n",
    "\n",
    "# execution\n",
    "data_frame = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what this data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation/notes</th>\n",
       "      <th>annotation/label/0</th>\n",
       "      <th>extras</th>\n",
       "      <th>metadata/first_done_at</th>\n",
       "      <th>metadata/last_updated_at</th>\n",
       "      <th>metadata/sec_taken</th>\n",
       "      <th>metadata/last_updated_by</th>\n",
       "      <th>metadata/status</th>\n",
       "      <th>metadata/evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  annotation/notes  \\\n",
       "0                             Get fucking real dude.               NaN   \n",
       "1  She is as dirty as they come  and that crook R...               NaN   \n",
       "2  why did you fuck it up. I could do it all day ...               NaN   \n",
       "3  Dude they dont finish enclosing the fucking sh...               NaN   \n",
       "4  WTF are you talking about Men? No men thats no...               NaN   \n",
       "\n",
       "   annotation/label/0  extras  metadata/first_done_at  \\\n",
       "0                   1     NaN           1527503426000   \n",
       "1                   1     NaN           1527503426000   \n",
       "2                   1     NaN           1527503426000   \n",
       "3                   1     NaN           1527503426000   \n",
       "4                   1     NaN           1527503426000   \n",
       "\n",
       "   metadata/last_updated_at  metadata/sec_taken      metadata/last_updated_by  \\\n",
       "0             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "1             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "2             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "3             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "4             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "\n",
       "  metadata/status metadata/evaluation  \n",
       "0            done                NONE  \n",
       "1            done                NONE  \n",
       "2            done                NONE  \n",
       "3            done                NONE  \n",
       "4            done                NONE  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check of the quantity of samples and the diversity of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation/notes</th>\n",
       "      <th>annotation/label/0</th>\n",
       "      <th>extras</th>\n",
       "      <th>metadata/first_done_at</th>\n",
       "      <th>metadata/last_updated_at</th>\n",
       "      <th>metadata/sec_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20001.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000100e+04</td>\n",
       "      <td>2.000100e+04</td>\n",
       "      <td>20001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.717817e+04</td>\n",
       "      <td>2.717817e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527504e+12</td>\n",
       "      <td>1.527504e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotation/notes  annotation/label/0  extras  metadata/first_done_at  \\\n",
       "count               0.0        20001.000000     0.0            2.000100e+04   \n",
       "mean                NaN            0.391080     NaN            1.527503e+12   \n",
       "std                 NaN            0.488005     NaN            2.717817e+04   \n",
       "min                 NaN            0.000000     NaN            1.527503e+12   \n",
       "25%                 NaN            0.000000     NaN            1.527503e+12   \n",
       "50%                 NaN            0.000000     NaN            1.527503e+12   \n",
       "75%                 NaN            1.000000     NaN            1.527503e+12   \n",
       "max                 NaN            1.000000     NaN            1.527504e+12   \n",
       "\n",
       "       metadata/last_updated_at  metadata/sec_taken  \n",
       "count              2.000100e+04             20001.0  \n",
       "mean               1.527503e+12                 0.0  \n",
       "std                2.717817e+04                 0.0  \n",
       "min                1.527503e+12                 0.0  \n",
       "25%                1.527503e+12                 0.0  \n",
       "50%                1.527503e+12                 0.0  \n",
       "75%                1.527503e+12                 0.0  \n",
       "max                1.527504e+12                 0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is a null value and all the indexes we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content                         0\n",
       "annotation/notes            20001\n",
       "annotation/label/0              0\n",
       "extras                      20001\n",
       "metadata/first_done_at          0\n",
       "metadata/last_updated_at        0\n",
       "metadata/sec_taken              0\n",
       "metadata/last_updated_by        0\n",
       "metadata/status                 0\n",
       "metadata/evaluation             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**annotation/notes**,**extras** is composed of null values so its implication in a classification algorithm is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['annotation/notes','extras'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at all the unique choices we have in all indexes, if there is an index that always has the same value we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content : ['Get fucking real dude.'\n",
      " \"She is as dirty as they come  and that crook Rengel  the Dems are so fucking corrupt it's a joke. Make Republicans look like  ...\"\n",
      " \"why did you fuck it up. I could do it all day too. Let's do it when you have an hour. Ping me later to sched writing a book here.\"\n",
      " ... 'hahahahaha >:) im evil mwahahahahahahahahaha'\n",
      " 'What&;s something unique about Ohio? :)'\n",
      " 'Who is the biggest gossiper you know?']\n",
      "annotation/label/0 : [1 0]\n",
      "metadata/first_done_at : [1527503426000 1527503427000 1527503428000 1527503429000 1527503430000\n",
      " 1527503431000 1527503432000 1527503433000 1527503434000 1527503435000\n",
      " 1527503436000 1527503437000 1527503438000 1527503439000 1527503440000\n",
      " 1527503441000 1527503442000 1527503443000 1527503444000 1527503445000\n",
      " 1527503446000 1527503447000 1527503448000 1527503449000 1527503450000\n",
      " 1527503451000 1527503452000 1527503453000 1527503454000 1527503455000\n",
      " 1527503456000 1527503457000 1527503458000 1527503459000 1527503460000\n",
      " 1527503461000 1527503462000 1527503463000 1527503464000 1527503465000\n",
      " 1527503466000 1527503467000 1527503468000 1527503469000 1527503470000\n",
      " 1527503471000 1527503472000 1527503473000 1527503474000 1527503475000\n",
      " 1527503476000 1527503477000 1527503478000 1527503479000 1527503480000\n",
      " 1527503481000 1527503482000 1527503483000 1527503484000 1527503485000\n",
      " 1527503486000 1527503487000 1527503488000 1527503489000 1527503490000\n",
      " 1527503491000 1527503492000 1527503493000 1527503494000 1527503495000\n",
      " 1527503496000 1527503497000 1527503498000 1527503499000 1527503500000\n",
      " 1527503501000 1527503502000 1527503503000 1527503504000 1527503505000\n",
      " 1527503506000 1527503507000 1527503508000 1527503509000 1527503510000\n",
      " 1527503511000 1527503512000 1527503513000 1527503514000 1527503515000\n",
      " 1527503516000 1527503517000 1527503518000 1527503519000]\n",
      "metadata/last_updated_at : [1527503426000 1527503427000 1527503428000 1527503429000 1527503430000\n",
      " 1527503431000 1527503432000 1527503433000 1527503434000 1527503435000\n",
      " 1527503436000 1527503437000 1527503438000 1527503439000 1527503440000\n",
      " 1527503441000 1527503442000 1527503443000 1527503444000 1527503445000\n",
      " 1527503446000 1527503447000 1527503448000 1527503449000 1527503450000\n",
      " 1527503451000 1527503452000 1527503453000 1527503454000 1527503455000\n",
      " 1527503456000 1527503457000 1527503458000 1527503459000 1527503460000\n",
      " 1527503461000 1527503462000 1527503463000 1527503464000 1527503465000\n",
      " 1527503466000 1527503467000 1527503468000 1527503469000 1527503470000\n",
      " 1527503471000 1527503472000 1527503473000 1527503474000 1527503475000\n",
      " 1527503476000 1527503477000 1527503478000 1527503479000 1527503480000\n",
      " 1527503481000 1527503482000 1527503483000 1527503484000 1527503485000\n",
      " 1527503486000 1527503487000 1527503488000 1527503489000 1527503490000\n",
      " 1527503491000 1527503492000 1527503493000 1527503494000 1527503495000\n",
      " 1527503496000 1527503497000 1527503498000 1527503499000 1527503500000\n",
      " 1527503501000 1527503502000 1527503503000 1527503504000 1527503505000\n",
      " 1527503506000 1527503507000 1527503508000 1527503509000 1527503510000\n",
      " 1527503511000 1527503512000 1527503513000 1527503514000 1527503515000\n",
      " 1527503516000 1527503517000 1527503518000 1527503519000]\n",
      "metadata/sec_taken : [0]\n",
      "metadata/last_updated_by : ['jI67aE5hwwdh6l16bcfFVnpyREd2']\n",
      "metadata/status : ['done']\n",
      "metadata/evaluation : ['NONE']\n"
     ]
    }
   ],
   "source": [
    "for index in data_frame.columns:\n",
    "        print(str(index) + \" : \" + str(data_frame[index].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata/sec_taken**,**metadata/last_updated_by**,**metadata/status**,**metadata/evaluation** is composed of a single variable so its implication in a classification algorithm is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['metadata/sec_taken','metadata/last_updated_by','metadata/status','metadata/evaluation'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata/last_updated_at**,**metadata/first_done_at** is composed of timestamp so it's implication in not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['metadata/last_updated_at','metadata/first_done_at'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation/label/0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  annotation/label/0\n",
       "0                             Get fucking real dude.                   1\n",
       "1  She is as dirty as they come  and that crook R...                   1\n",
       "2  why did you fuck it up. I could do it all day ...                   1\n",
       "3  Dude they dont finish enclosing the fucking sh...                   1\n",
       "4  WTF are you talking about Men? No men thats no...                   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns for easier use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.rename(columns={\"content\" : \"sentence\",\"annotation/label/0\" :\"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text may contain numbers, special characters, and unwanted spaces. We will remove all the special characters, numbers, and unwanted spaces from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer \n",
    "stemmer = WordNetLemmatizer()\n",
    "# Function to apply on our sentence\n",
    "def converterSentence(text):\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # remove all single characters\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # Converting to Lowercase\n",
    "    text = text.lower()\n",
    "    # Lemmatization\n",
    "    text = text.split()\n",
    "    text = [stemmer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    get fucking real dude\n",
       "1        she is a dirty a they come and that crook reng...\n",
       "2        why did you fuck it up could do it all day too...\n",
       "3        dude they dont finish enclosing the fucking sh...\n",
       "4        wtf are you talking about men no men thats not...\n",
       "5        ill save you the trouble sister here come big ...\n",
       "6        im dead serious real athlete never cheat don e...\n",
       "7        go absolutely insane hate to be the bearer of ...\n",
       "8        lmao im watching the same thing ahaha the gay ...\n",
       "9        lol no he said what do you call jail cell to g...\n",
       "10       truth on both count that guy is an as and thei...\n",
       "11                                        shakespeare nerd\n",
       "12                               you are such fucking dork\n",
       "13                                       heh fuck em where\n",
       "14                         damn it totally forgot that one\n",
       "15                    wow damn would have been pissed that\n",
       "16               nigga geigh lmao fuck yo final beeeeeitch\n",
       "17                                               that suck\n",
       "18       read that this morning my fav is how they just...\n",
       "19                  unibroue 17 another damn good unibroue\n",
       "20       damn your evil 60 minute ipa beckoning me from...\n",
       "21       it did then my fucking dad turned it off just ...\n",
       "22                         it pretty much is fuck you card\n",
       "23                                 that karma is bitch huh\n",
       "24              don get too fat or you ll turn into boomer\n",
       "25       the hormone are worse for guy cant tell you ho...\n",
       "26       except for joe jonas the as munch who broke up...\n",
       "27       man that rly suck for 1 am positive that all w...\n",
       "28          hard to kick as yourself with slipper on on it\n",
       "29       thats pretty damn awesome very smart aaronage ...\n",
       "                               ...                        \n",
       "19971                      not really when first meet them\n",
       "19972                           lykee ohhemmgee hiii mikey\n",
       "19973             are you picky about spelling and grammar\n",
       "19974              popcorn twizzlers and some mike and ike\n",
       "19975    ohhh well didnt know you were doing that you k...\n",
       "19976            do you wish someone wa with you right now\n",
       "19977                                        kohl actually\n",
       "19978       yes but we end up warped in the end either way\n",
       "19979                                entertainingly cheesy\n",
       "19980             do you think you apos re hot and or sexy\n",
       "19981                                               repeat\n",
       "19982    cannot listen to that heavy metal like me some...\n",
       "19983                    do no alix sister ha cruch on you\n",
       "19984                                               repeat\n",
       "19985                                          hey who diz\n",
       "19986    aint da one dat said da tampon thang but added...\n",
       "19987                       how many language do you speak\n",
       "19988                               lol no idnt iguess bih\n",
       "19989     sometimes did that lot when wa sick this past wk\n",
       "19990                                   you ll neverr know\n",
       "19991                                     hold im confused\n",
       "19992                                    wouldnt catch one\n",
       "19993    haha nahh ive just fractured some thumb bhut i...\n",
       "19994             did we have any class together this year\n",
       "19995                       havent gotten 2 that part haha\n",
       "19996    dont but what is complaining about it going to do\n",
       "19997    bahah yeah totally just gonna get pissed at yo...\n",
       "19998             hahahahaha im evil mwahahahahahahahahaha\n",
       "19999                     what something unique about ohio\n",
       "20000                 who is the biggest gossiper you know\n",
       "Name: sentence, Length: 20001, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['sentence']= data_frame.sentence.apply(converterSentence)\n",
    "data_frame.sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different approaches exist to convert text into the corresponding numerical form. But we are going to use Bag of Words Model because it is the most efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default Vectorizer & Default model to have a first overview of the result** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data_frame.sentence)\n",
    "Y = data_frame.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag of words approach works fine for converting text to numbers. However, it has one drawback. It assigns a score to a word based on its occurrence in a particular document. It doesn't take into account the fact that the word might also be having a high frequency of occurrence in other documents as well. TFIDF resolves this issue by multiplying the term frequency of a word by the inverse document frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to find parameters for the vectorizer which could impact the model. But the sentences being too small the min_df and max_df parameters are useless here. We still just tried to vary the number of features but that did not affect the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_MIN_DEF= [x/100 for x in range(1,50,5)]\n",
    "LIST_MAX_DEF= [x for x in range(90,100)]\n",
    "LIST_MAX_DEF.reverse()\n",
    "LIST_MAX_FEATURES = [x for x in range(100,2000,50)]\n",
    "def customVectorizer(listMinDef=LIST_MIN_DEF,listMaxDef=LIST_MAX_DEF,listMaxFeatures=LIST_MAX_FEATURES):\n",
    "    listVectorizer = []\n",
    "    for maxFeatures in listMaxFeatures:\n",
    "        listVectorizer.append(CountVectorizer(stop_words='english',max_features=maxFeatures))  \n",
    "    return listVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the result of this function in a file located in the data folder, just for information there is just marked the same for each variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary vectorizer parameters to see if it impacts the default Random Forest model\n",
    "def ImpactOfVectorizer():\n",
    "    fichier = open(\"data/dataRFCDefaultCustomVectorizer.txt\", \"a\")\n",
    "    for vecto in customVectorizer():\n",
    "        vectorizer = vecto\n",
    "        X = vectorizer.fit_transform(data_frame.sentence)\n",
    "        Y = data_frame.label\n",
    "        tfidfconverter = TfidfTransformer()\n",
    "        X = tfidfconverter.fit_transform(X)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "        # Simple Random Forest Classifier\n",
    "        classifier = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "        classifier.fit(x_train, y_train) \n",
    "        crboost = classification_report(y_test,y_pred,digits=10,output_dict=True)\n",
    "        fichier.write(str(crboost['0']['precision'])+\" \" +str(crboost['1']['precision'])+\"\\n\")\n",
    "    fichier.close()\n",
    "# The famous line that saves you 5 s               \n",
    "# ImpactOfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result :\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The answer to the question “What machine learning model should I use?” is always “It depends.” Even the most experienced data scientists can’t tell which algorithm will perform best before experimenting them.\"\n",
    "\n",
    "In order to find the optimum model, we tried to make as many models as possible to know which would be the best. Here are the 6 models that were made.\n",
    "\n",
    "MLPClassifier, DecisionTreeClassifier, RandomForestClassifier, KNeighborsClassifier, LogisticRegression and finally SVM (Support Vector Machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these trains and tests for all our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data_frame.sentence)\n",
    "Y = data_frame.label\n",
    "# TFID\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)\n",
    "# SPLIT\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model aims to optimize the log-loss function using LBGFGS or stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the default neural network (45 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\singl\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMLP = MLPClassifier()\n",
    "modelMLP.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the trained network to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = modelMLP.predict(x_test)\n",
    "modelMLP.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2911,  751],\n",
       "       [ 183, 2156]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86      3662\n",
      "           1       0.74      0.92      0.82      2339\n",
      "\n",
      "    accuracy                           0.84      6001\n",
      "   macro avg       0.84      0.86      0.84      6001\n",
      "weighted avg       0.86      0.84      0.85      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to find more optimal parameters, with the magic GridSearchCV multi-threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMLP = MLPClassifier()\n",
    "parameter_space = {'activation': ['logistic','tanh', 'relu'],\n",
    "                  'hidden_layer_sizes':[i for i in range(1,220,20)],\n",
    "                  'alpha':[0.0001,0.001,0.01,0.1,1],\n",
    "                  'max_iter':[50, 100, 150, 200]}\n",
    "gridSearch = GridSearchCV(modelMLP, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters set\n",
    "print('Best parameters found:\\n', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All results\n",
    "means = gridSearch.cv_results_['mean_test_score']\n",
    "stds = gridSearch.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearch.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve the performances of this classifier, we will look at how accuracy evolves when we change the size of the test set, the number of hidden layer of the classifier or the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, the function to change the size of the test set.\n",
    "def calculate_test_size(X, y, o):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=o)\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(X_train)\n",
    "\n",
    "\tscaler.transform(X_train)\n",
    "\tscaler.transform(X_test)\n",
    "\tmlp= MLPClassifier(hidden_layer_sizes=(3, 13), max_iter=500)\n",
    "\tmlp.fit(X_train, y_train.ravel())\n",
    "\tpredictions = mlp.predict(X_test)\n",
    "\n",
    "\treturn accuracy_score(y_test, predictions)\n",
    "\n",
    "#Next, the function to change the number of the hidden layer.\n",
    "def calculate_hidden(X, y, o):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33)\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(X_train)\n",
    "\n",
    "\tscaler.transform(X_train)\n",
    "\tscaler.transform(X_test)\n",
    "\tmlp= MLPClassifier(hidden_layer_sizes=(3, o), max_iter=500)\n",
    "\tmlp.fit(X_train, y_train.ravel())\n",
    "\tpredictions = m\n",
    "    lp.predict(X_test)\n",
    "\n",
    "\treturn accuracy_score(y_test, predictions)\n",
    "\n",
    "#Finally, the function to change the number of iteration.\n",
    "def calculate_it(X, y, o):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33)\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(X_train)\n",
    "\n",
    "\tscaler.transform(X_train)\n",
    "\tscaler.transform(X_test)\n",
    "\tmlp= MLPClassifier(hidden_layer_sizes=(3, 13), max_iter=o)\n",
    "\tmlp.fit(X_train, y_train.ravel())\n",
    "\tpredictions = mlp.predict(X_test)\n",
    "\n",
    "\treturn accuracy_score(y_test, predictions)\n",
    "\n",
    "test_size = np.arange(0.1, 1, .1)\n",
    "size_o_test = [calculate_test_size(X, Y, i) for i in test_size]\n",
    "\n",
    "hidden_test = np.arange(5, 50, 5)\n",
    "hidd_of_test = [calculate_hidden(X, Y, i) for i in hidden_test]\n",
    "\n",
    "it_test = np.arange(100, 1000, 50)\n",
    "it_of_test = [calculate_it(X, Y, i) for i in it_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the purpose to visualize its results, we are now going to display them in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_size, size_o_test)\n",
    "plt.title(\"Experimentation on test size\")\n",
    "plt.xlabel(\"Size of test set\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hidden_test, hidd_of_test)\n",
    "plt.title(\"Experimentation on number of hidden layers\")\n",
    "plt.xlabel(\"Number of hidden layer\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(it_test, it_of_test)\n",
    "plt.title(\"Experimentation on number of iteration\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classification is used in statistics to model the probability of a certain class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the default one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = modelLR.predict(x_test)\n",
    "modelLR.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3204,  458],\n",
       "       [ 982, 1357]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      0.87      0.82      3662\n",
      "          1       0.75      0.58      0.65      2339\n",
      "\n",
      "avg / total       0.76      0.76      0.75      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to add hyperparameter to get a better accuracy.\n",
    "\n",
    "For this one, 5 hyperparameters : C, penality, max_iter,solver and tol.(5-10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'max_iter': [50, 100, 150, 200],\n",
       "                         'penalty': ['l1', 'l2'], 'solver': ['liblinear'],\n",
       "                         'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLR = LogisticRegression()\n",
    "parameter_space = {'penalty': ['l1','l2'],\n",
    "                  'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'max_iter':[50, 100, 150, 200],\n",
    "                  'tol':[0.00001,0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
    "                  'solver' : ['liblinear']}\n",
    "gridSearchLR = GridSearchCV(modelLR, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearchLR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', gridSearchLR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.665 (+/-0.015) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.641 (+/-0.011) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.667 (+/-0.009) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.667 (+/-0.009) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.665 (+/-0.007) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.661 (+/-0.012) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.667 (+/-0.014) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.666 (+/-0.016) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.654 (+/-0.019) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.667 (+/-0.009) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.667 (+/-0.009) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.665 (+/-0.007) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.661 (+/-0.012) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.667 (+/-0.013) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.666 (+/-0.015) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.651 (+/-0.013) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.667 (+/-0.009) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.667 (+/-0.009) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.665 (+/-0.007) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.661 (+/-0.012) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.668 (+/-0.012) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.666 (+/-0.013) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.657 (+/-0.027) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.667 (+/-0.009) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.667 (+/-0.009) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.665 (+/-0.007) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.661 (+/-0.012) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.717 (+/-0.021) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.719 (+/-0.020) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.711 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.740 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.674 (+/-0.014) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.717 (+/-0.021) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.718 (+/-0.022) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.705 (+/-0.018) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.740 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.674 (+/-0.014) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.717 (+/-0.021) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.718 (+/-0.023) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.711 (+/-0.013) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.740 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.674 (+/-0.014) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.717 (+/-0.021) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.717 (+/-0.022) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.710 (+/-0.018) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.740 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.674 (+/-0.014) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.825 (+/-0.009) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.819 (+/-0.012) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.776 (+/-0.009) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.820 (+/-0.012) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.792 (+/-0.026) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.825 (+/-0.008) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.825 (+/-0.007) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.816 (+/-0.012) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.780 (+/-0.008) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.820 (+/-0.012) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.792 (+/-0.026) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.825 (+/-0.008) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.820 (+/-0.011) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.777 (+/-0.012) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.820 (+/-0.012) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.792 (+/-0.026) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.824 (+/-0.007) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.820 (+/-0.012) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.777 (+/-0.012) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.820 (+/-0.012) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.792 (+/-0.026) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.803 (+/-0.007) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.803 (+/-0.007) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.801 (+/-0.005) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.795 (+/-0.009) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.788 (+/-0.017) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.766 (+/-0.015) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.813 (+/-0.011) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.817 (+/-0.007) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.797 (+/-0.014) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.803 (+/-0.008) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.803 (+/-0.008) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.801 (+/-0.006) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.795 (+/-0.007) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.789 (+/-0.012) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.761 (+/-0.013) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.813 (+/-0.011) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.817 (+/-0.007) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.797 (+/-0.014) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.804 (+/-0.008) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.803 (+/-0.008) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.801 (+/-0.006) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.795 (+/-0.008) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.787 (+/-0.012) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.762 (+/-0.004) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.813 (+/-0.011) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.817 (+/-0.007) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.797 (+/-0.014) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n",
      "0.803 (+/-0.007) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.803 (+/-0.008) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.801 (+/-0.005) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.795 (+/-0.006) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.787 (+/-0.016) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.763 (+/-0.007) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'solver': 'liblinear', 'tol': 10}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1e-05}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.0001}\n",
      "0.813 (+/-0.011) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.001}\n",
      "0.817 (+/-0.007) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.01}\n",
      "0.797 (+/-0.014) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'solver': 'liblinear', 'tol': 10}\n"
     ]
    }
   ],
   "source": [
    "# All results\n",
    "means = gridSearchLR.cv_results_['mean_test_score']\n",
    "stds = gridSearchLR.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearchLR.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the results of the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3166,  496],\n",
       "       [ 306, 2033]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLR = LogisticRegression(C=10,max_iter=100,penalty='l1',tol=1e-05,solver='liblinear')\n",
    "modelLR.fit(x_train,y_train)\n",
    "y_pred = modelLR.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89      3662\n",
      "           1       0.80      0.87      0.84      2339\n",
      "\n",
      "    accuracy                           0.87      6001\n",
      "   macro avg       0.86      0.87      0.86      6001\n",
      "weighted avg       0.87      0.87      0.87      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate the average performance of our model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Precision : 0.8576991401368539\n",
      "Avg Precision : 0.8576991401368537\n"
     ]
    }
   ],
   "source": [
    "# Calcul real efficient of the model\n",
    "def functionRealPerf(numberRun):\n",
    "    listPrecision= []\n",
    "    for i in range(numberRun):\n",
    "        modelLR = LogisticRegression(C=10,max_iter=100,penalty='l1',tol=1e-05,solver='liblinear')\n",
    "        modelLR.fit(x_train,y_train)\n",
    "        y_pred = modelLR.predict(x_test)\n",
    "        cr = classification_report(y_test,y_pred,digits=10,output_dict=True)\n",
    "        listPrecision.append((cr['0']['precision']+cr['1']['precision'])/2)\n",
    "    print(\"Max Precision : \" + str(max(listPrecision)))\n",
    "    print(\"Avg Precision : \" + str(sum(listPrecision)/numberRun))\n",
    "functionRealPerf(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(cv=5, random_state=0).fit(x_train, y_train)\n",
    "y_pred =clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.85      0.88      3662\n",
      "          1       0.79      0.87      0.83      2339\n",
      "\n",
      "avg / total       0.86      0.86      0.86      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = classification_report(y_test,y_pred)\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KneighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier uses the k-nearest neighbors method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go for execution by default.(25min-10h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelKNC = KNeighborsClassifier()\n",
    "modelKNC.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = modelKNC .predict(x_test)\n",
    "modelKNC .score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3453,  209],\n",
       "       [1661,  678]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.94      0.79      3662\n",
      "           1       0.76      0.29      0.42      2339\n",
      "\n",
      "    accuracy                           0.69      6001\n",
      "   macro avg       0.72      0.62      0.60      6001\n",
      "weighted avg       0.71      0.69      0.64      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again it's time to do magic and find the best hyperparameters. We will try to vary the algorithm parameter, n_neighbors and weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'algorithm': ['ball_tree', 'auto', 'kd_tree', 'brute'],\n",
       "                         'n_neighbors': [30, 40, 50, 60, 70, 80, 90],\n",
       "                         'weights': ['distance', 'uniform']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelKN = KNeighborsClassifier()\n",
    "parameter_space = {'algorithm': ['ball_tree','auto', 'kd_tree', 'brute'],\n",
    "                  'n_neighbors':[i for i in range(30,100,10)],\n",
    "                  'weights':['distance','uniform']}\n",
    "gridSearchKN = GridSearchCV(modelKN, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearchKN.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the best result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'algorithm': 'ball_tree', 'n_neighbors': 90, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', gridSearchKN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874 (+/-0.007) for {'algorithm': 'ball_tree', 'n_neighbors': 30, 'weights': 'distance'}\n",
      "0.624 (+/-0.005) for {'algorithm': 'ball_tree', 'n_neighbors': 30, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'ball_tree', 'n_neighbors': 40, 'weights': 'distance'}\n",
      "0.623 (+/-0.006) for {'algorithm': 'ball_tree', 'n_neighbors': 40, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'}\n",
      "0.621 (+/-0.005) for {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'ball_tree', 'n_neighbors': 60, 'weights': 'distance'}\n",
      "0.621 (+/-0.005) for {'algorithm': 'ball_tree', 'n_neighbors': 60, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'ball_tree', 'n_neighbors': 70, 'weights': 'distance'}\n",
      "0.621 (+/-0.004) for {'algorithm': 'ball_tree', 'n_neighbors': 70, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'ball_tree', 'n_neighbors': 80, 'weights': 'distance'}\n",
      "0.619 (+/-0.006) for {'algorithm': 'ball_tree', 'n_neighbors': 80, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'ball_tree', 'n_neighbors': 90, 'weights': 'distance'}\n",
      "0.617 (+/-0.004) for {'algorithm': 'ball_tree', 'n_neighbors': 90, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'auto', 'n_neighbors': 30, 'weights': 'distance'}\n",
      "0.624 (+/-0.005) for {'algorithm': 'auto', 'n_neighbors': 30, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'auto', 'n_neighbors': 40, 'weights': 'distance'}\n",
      "0.623 (+/-0.006) for {'algorithm': 'auto', 'n_neighbors': 40, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'}\n",
      "0.621 (+/-0.005) for {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'auto', 'n_neighbors': 60, 'weights': 'distance'}\n",
      "0.621 (+/-0.005) for {'algorithm': 'auto', 'n_neighbors': 60, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'auto', 'n_neighbors': 70, 'weights': 'distance'}\n",
      "0.621 (+/-0.004) for {'algorithm': 'auto', 'n_neighbors': 70, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'auto', 'n_neighbors': 80, 'weights': 'distance'}\n",
      "0.619 (+/-0.006) for {'algorithm': 'auto', 'n_neighbors': 80, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'auto', 'n_neighbors': 90, 'weights': 'distance'}\n",
      "0.617 (+/-0.004) for {'algorithm': 'auto', 'n_neighbors': 90, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'kd_tree', 'n_neighbors': 30, 'weights': 'distance'}\n",
      "0.624 (+/-0.005) for {'algorithm': 'kd_tree', 'n_neighbors': 30, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'kd_tree', 'n_neighbors': 40, 'weights': 'distance'}\n",
      "0.623 (+/-0.006) for {'algorithm': 'kd_tree', 'n_neighbors': 40, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'kd_tree', 'n_neighbors': 50, 'weights': 'distance'}\n",
      "0.621 (+/-0.005) for {'algorithm': 'kd_tree', 'n_neighbors': 50, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'kd_tree', 'n_neighbors': 60, 'weights': 'distance'}\n",
      "0.621 (+/-0.005) for {'algorithm': 'kd_tree', 'n_neighbors': 60, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'kd_tree', 'n_neighbors': 70, 'weights': 'distance'}\n",
      "0.621 (+/-0.004) for {'algorithm': 'kd_tree', 'n_neighbors': 70, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'kd_tree', 'n_neighbors': 80, 'weights': 'distance'}\n",
      "0.619 (+/-0.006) for {'algorithm': 'kd_tree', 'n_neighbors': 80, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'kd_tree', 'n_neighbors': 90, 'weights': 'distance'}\n",
      "0.617 (+/-0.004) for {'algorithm': 'kd_tree', 'n_neighbors': 90, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'brute', 'n_neighbors': 30, 'weights': 'distance'}\n",
      "0.624 (+/-0.005) for {'algorithm': 'brute', 'n_neighbors': 30, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'brute', 'n_neighbors': 40, 'weights': 'distance'}\n",
      "0.623 (+/-0.006) for {'algorithm': 'brute', 'n_neighbors': 40, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'brute', 'n_neighbors': 50, 'weights': 'distance'}\n",
      "0.621 (+/-0.005) for {'algorithm': 'brute', 'n_neighbors': 50, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'brute', 'n_neighbors': 60, 'weights': 'distance'}\n",
      "0.621 (+/-0.005) for {'algorithm': 'brute', 'n_neighbors': 60, 'weights': 'uniform'}\n",
      "0.874 (+/-0.006) for {'algorithm': 'brute', 'n_neighbors': 70, 'weights': 'distance'}\n",
      "0.621 (+/-0.004) for {'algorithm': 'brute', 'n_neighbors': 70, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'brute', 'n_neighbors': 80, 'weights': 'distance'}\n",
      "0.619 (+/-0.006) for {'algorithm': 'brute', 'n_neighbors': 80, 'weights': 'uniform'}\n",
      "0.874 (+/-0.007) for {'algorithm': 'brute', 'n_neighbors': 90, 'weights': 'distance'}\n",
      "0.617 (+/-0.004) for {'algorithm': 'brute', 'n_neighbors': 90, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# All results\n",
    "means = gridSearchKN.cv_results_['mean_test_score']\n",
    "stds = gridSearchKN.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearchKN.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the results of the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3621,   41],\n",
       "       [ 303, 2036]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelKN = KNeighborsClassifier(algorithm = 'ball_tree', n_neighbors=90, weights = 'distance')\n",
    "modelKN.fit(x_train,y_train)\n",
    "y_pred = modelKN.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate the average performance of our model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Precision : 0.951521432494232\n",
      "Avg Precision : 0.951521432494232\n"
     ]
    }
   ],
   "source": [
    "# Calcul real efficient of the model\n",
    "def functionRealPerf(numberRun):\n",
    "    listPrecision= []\n",
    "    for i in range(numberRun):\n",
    "        modelKN = KNeighborsClassifier(algorithm = 'ball_tree', n_neighbors=90, weights = 'distance')\n",
    "        modelKN.fit(x_train, y_train)\n",
    "        y_pred = modelKN.predict(x_test)\n",
    "        cr = classification_report(y_test,y_pred,digits=10,output_dict=True)\n",
    "        listPrecision.append((cr['0']['precision']+cr['1']['precision'])/2)\n",
    "    print(\"Max Precision : \" + str(max(listPrecision)))\n",
    "    print(\"Avg Precision : \" + str(sum(listPrecision)/numberRun))\n",
    "warnings.filterwarnings('ignore')\n",
    "functionRealPerf(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM algorithm finds the right hyperplans that differentiate classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3114,  548],\n",
       "       [ 370, 1969]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSVC = LinearSVC(random_state=0, tol=1e-5)\n",
    "modelSVC.fit(x_train, y_train)\n",
    "y_pred = modelSVC.predict(x_test)\n",
    "conf_matrix_clf = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSVC.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87      3662\n",
      "           1       0.78      0.84      0.81      2339\n",
      "\n",
      "    accuracy                           0.85      6001\n",
      "   macro avg       0.84      0.85      0.84      6001\n",
      "weighted avg       0.85      0.85      0.85      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_modelSVC = classification_report(y_test, y_pred)\n",
    "print(class_modelSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are still going to look for the best hyperparameters to maximize performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=1000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.51, 1.01, 1.51, 2.01, 2.51, 3.01, 3.51,\n",
       "                               4.01, 4.51],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'tol': [1, 0.1, 0.01, 0.001, 0.0001, 1e-06]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSVC = LinearSVC()\n",
    "parameter_space = {'penalty': ['l1','l2'],\n",
    "                  'tol':[1,0.1,0.01,0.001,0.0001,0.000001],\n",
    "                  'C':[x/100 for x in range(1,500,50)]}\n",
    "gridSearchSVC = GridSearchCV(modelSVC, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearchSVC.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'C': 1.01, 'penalty': 'l2', 'tol': 1}\n"
     ]
    }
   ],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', gridSearchSVC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874 (+/-0.007) for {'C': 0.01, 'penalty': 'l1', 'tol': 1}\n",
      "0.624 (+/-0.005) for {'C': 0.01, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.874 (+/-0.006) for {'C': 0.01, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.623 (+/-0.006) for {'C': 0.01, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.874 (+/-0.006) for {'C': 0.01, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.621 (+/-0.005) for {'C': 0.01, 'penalty': 'l1', 'tol': 1e-06}\n",
      "0.874 (+/-0.006) for {'C': 0.01, 'penalty': 'l2', 'tol': 1}\n",
      "0.621 (+/-0.005) for {'C': 0.01, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.874 (+/-0.006) for {'C': 0.01, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.621 (+/-0.004) for {'C': 0.01, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.874 (+/-0.007) for {'C': 0.01, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.619 (+/-0.006) for {'C': 0.01, 'penalty': 'l2', 'tol': 1e-06}\n",
      "0.874 (+/-0.007) for {'C': 0.51, 'penalty': 'l1', 'tol': 1}\n",
      "0.617 (+/-0.004) for {'C': 0.51, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.874 (+/-0.007) for {'C': 0.51, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.624 (+/-0.005) for {'C': 0.51, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.874 (+/-0.006) for {'C': 0.51, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.623 (+/-0.006) for {'C': 0.51, 'penalty': 'l1', 'tol': 1e-06}\n",
      "0.874 (+/-0.006) for {'C': 0.51, 'penalty': 'l2', 'tol': 1}\n",
      "0.621 (+/-0.005) for {'C': 0.51, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.874 (+/-0.006) for {'C': 0.51, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.621 (+/-0.005) for {'C': 0.51, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.874 (+/-0.006) for {'C': 0.51, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.621 (+/-0.004) for {'C': 0.51, 'penalty': 'l2', 'tol': 1e-06}\n",
      "0.874 (+/-0.007) for {'C': 1.01, 'penalty': 'l1', 'tol': 1}\n",
      "0.619 (+/-0.006) for {'C': 1.01, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.874 (+/-0.007) for {'C': 1.01, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.617 (+/-0.004) for {'C': 1.01, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.874 (+/-0.007) for {'C': 1.01, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.624 (+/-0.005) for {'C': 1.01, 'penalty': 'l1', 'tol': 1e-06}\n",
      "0.874 (+/-0.006) for {'C': 1.01, 'penalty': 'l2', 'tol': 1}\n",
      "0.623 (+/-0.006) for {'C': 1.01, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.874 (+/-0.006) for {'C': 1.01, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.621 (+/-0.005) for {'C': 1.01, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.874 (+/-0.006) for {'C': 1.01, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.621 (+/-0.005) for {'C': 1.01, 'penalty': 'l2', 'tol': 1e-06}\n",
      "0.874 (+/-0.006) for {'C': 1.51, 'penalty': 'l1', 'tol': 1}\n",
      "0.621 (+/-0.004) for {'C': 1.51, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.874 (+/-0.007) for {'C': 1.51, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.619 (+/-0.006) for {'C': 1.51, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.874 (+/-0.007) for {'C': 1.51, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.617 (+/-0.004) for {'C': 1.51, 'penalty': 'l1', 'tol': 1e-06}\n",
      "0.874 (+/-0.007) for {'C': 1.51, 'penalty': 'l2', 'tol': 1}\n",
      "0.624 (+/-0.005) for {'C': 1.51, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.874 (+/-0.006) for {'C': 1.51, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.623 (+/-0.006) for {'C': 1.51, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.874 (+/-0.006) for {'C': 1.51, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.621 (+/-0.005) for {'C': 1.51, 'penalty': 'l2', 'tol': 1e-06}\n",
      "0.874 (+/-0.006) for {'C': 2.01, 'penalty': 'l1', 'tol': 1}\n",
      "0.621 (+/-0.005) for {'C': 2.01, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.874 (+/-0.006) for {'C': 2.01, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.621 (+/-0.004) for {'C': 2.01, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.874 (+/-0.007) for {'C': 2.01, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.619 (+/-0.006) for {'C': 2.01, 'penalty': 'l1', 'tol': 1e-06}\n",
      "0.874 (+/-0.007) for {'C': 2.01, 'penalty': 'l2', 'tol': 1}\n",
      "0.617 (+/-0.004) for {'C': 2.01, 'penalty': 'l2', 'tol': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# All results\n",
    "means = gridSearchKN.cv_results_['mean_test_score']\n",
    "stds = gridSearchKN.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearchSVC.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the results of the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3033,  629],\n",
       "       [ 275, 2064]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelSVC = LinearSVC(C= 2.01,penalty='l2',tol= 1)\n",
    "modelSVC.fit(x_train, y_train)\n",
    "y_pred = modelSVC.predict(x_test)\n",
    "conf_matrix_clf = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.83      0.87      3662\n",
      "           1       0.77      0.88      0.82      2339\n",
      "\n",
      "    accuracy                           0.85      6001\n",
      "   macro avg       0.84      0.86      0.85      6001\n",
      "weighted avg       0.86      0.85      0.85      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_modelSVC = classification_report(y_test, y_pred)\n",
    "print(class_modelSVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate the average performance of our model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Precision : 0.8493638142026139\n",
      "Avg Precision : 0.8437684782984839\n"
     ]
    }
   ],
   "source": [
    "# Calcul real efficient of the model\n",
    "def functionRealPerf(numberRun):\n",
    "    listPrecision= []\n",
    "    for i in range(numberRun):\n",
    "        modelSVC = LinearSVC(C= 2.01,penalty='l2',tol= 1)\n",
    "        modelSVC.fit(x_train, y_train)\n",
    "        y_pred = modelSVC.predict(x_test)\n",
    "        cr = classification_report(y_test,y_pred,digits=10,output_dict=True)\n",
    "        listPrecision.append((cr['0']['precision']+cr['1']['precision'])/2)\n",
    "    print(\"Max Precision : \" + str(max(listPrecision)))\n",
    "    print(\"Avg Precision : \" + str(sum(listPrecision)/numberRun))\n",
    "functionRealPerf(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go for execution by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2960,  702],\n",
       "       [ 187, 2152]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDTC = DecisionTreeClassifier()\n",
    "modelDTC.fit(x_train, y_train) \n",
    "y_pred = modelDTC.predict(x_test)\n",
    "conf_matrix_clf = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = modelDTC.predict(x_test)\n",
    "modelDTC.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      0.81      0.87      3662\n",
      "          1       0.75      0.92      0.83      2339\n",
      "\n",
      "avg / total       0.87      0.85      0.85      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One advantage of this model is that we can visualize the decision tree built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DOT data\n",
    "dot_data = tree.export_graphviz(modelDTC, out_file=None,   \n",
    "                                class_names=['Not Cyber-Troll', 'Cyber-Troll'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw graph\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "#Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PNG\n",
    "#graph.write_png(\"tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will vary the criterion, max_features, min_samples_leaf and max_depth parameters to maximize the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features=None,\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              presort='deprecated',\n",
       "                                              random_state=None,\n",
       "                                              splitter='best'),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [1, 6, 11, 16, 21, 26, 31, 36, 41, 46],\n",
       "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDTC = DecisionTreeClassifier()\n",
    "parameter_space = {'criterion': ['gini', 'entropy'],\n",
    "                  'max_features':[\"auto\", \"sqrt\", \"log2\"],\n",
    "                  'min_samples_leaf':[ i for i in range(1,50,5)],\n",
    "                  'max_depth' : [ i for i in range(1,50,5)]}\n",
    "gridSearchDTC = GridSearchCV(modelDTC, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearchDTC.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 1}\n"
     ]
    }
   ],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', gridSearchDTC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.610 (+/-0.003) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.610 (+/-0.007) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.613 (+/-0.011) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.606 (+/-0.009) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.613 (+/-0.010) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.614 (+/-0.008) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.001) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.611 (+/-0.007) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.001) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.002) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.001) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.001) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.610 (+/-0.002) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.618 (+/-0.009) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.622 (+/-0.017) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.621 (+/-0.025) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.610 (+/-0.010) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.612 (+/-0.011) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.614 (+/-0.013) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.616 (+/-0.005) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.611 (+/-0.005) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.616 (+/-0.019) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.612 (+/-0.002) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.619 (+/-0.016) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.610 (+/-0.009) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.610 (+/-0.002) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.617 (+/-0.010) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.610 (+/-0.004) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.610 (+/-0.004) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.616 (+/-0.019) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.612 (+/-0.011) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.612 (+/-0.008) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.609 (+/-0.003) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.001) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.607 (+/-0.002) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.609 (+/-0.002) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.615 (+/-0.007) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.614 (+/-0.011) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.638 (+/-0.018) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.627 (+/-0.030) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.610 (+/-0.007) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.612 (+/-0.008) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.001) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.610 (+/-0.005) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.628 (+/-0.031) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.613 (+/-0.013) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.618 (+/-0.005) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.617 (+/-0.006) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.620 (+/-0.018) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.617 (+/-0.007) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.628 (+/-0.033) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.611 (+/-0.003) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.615 (+/-0.013) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.610 (+/-0.006) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.609 (+/-0.002) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.612 (+/-0.012) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.609 (+/-0.003) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.618 (+/-0.007) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.631 (+/-0.002) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.625 (+/-0.022) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.619 (+/-0.015) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.609 (+/-0.002) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.628 (+/-0.039) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.616 (+/-0.010) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.620 (+/-0.029) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.610 (+/-0.005) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.617 (+/-0.012) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.624 (+/-0.015) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.621 (+/-0.019) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.625 (+/-0.013) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.620 (+/-0.031) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.616 (+/-0.015) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.616 (+/-0.017) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.002) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.615 (+/-0.009) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.004) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.011) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.611 (+/-0.004) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.002) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.609 (+/-0.003) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.609 (+/-0.002) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.630 (+/-0.015) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.624 (+/-0.041) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.624 (+/-0.016) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.623 (+/-0.012) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.616 (+/-0.006) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.618 (+/-0.016) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.613 (+/-0.009) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.611 (+/-0.006) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.614 (+/-0.011) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.637 (+/-0.046) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.621 (+/-0.028) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.622 (+/-0.015) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.629 (+/-0.005) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.611 (+/-0.004) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.626 (+/-0.025) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.615 (+/-0.015) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.610 (+/-0.005) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.612 (+/-0.013) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.607 (+/-0.001) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.615 (+/-0.021) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.606 (+/-0.006) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.612 (+/-0.011) for {'criterion': 'gini', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.631 (+/-0.003) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.625 (+/-0.019) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.633 (+/-0.013) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.622 (+/-0.019) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.622 (+/-0.006) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.001) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.612 (+/-0.008) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.619 (+/-0.015) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.611 (+/-0.007) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.609 (+/-0.002) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.637 (+/-0.023) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.635 (+/-0.021) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.623 (+/-0.022) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.622 (+/-0.019) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.615 (+/-0.014) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.616 (+/-0.013) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.618 (+/-0.004) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.606 (+/-0.009) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.618 (+/-0.016) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.005) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.625 (+/-0.032) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.002) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.611 (+/-0.008) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.635 (+/-0.034) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.639 (+/-0.034) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.636 (+/-0.022) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.627 (+/-0.010) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.615 (+/-0.011) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.611 (+/-0.010) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.610 (+/-0.001) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.616 (+/-0.033) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.613 (+/-0.012) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.610 (+/-0.005) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.636 (+/-0.018) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.628 (+/-0.021) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.627 (+/-0.013) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.647 (+/-0.027) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.626 (+/-0.013) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.610 (+/-0.003) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.612 (+/-0.006) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.625 (+/-0.050) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.609 (+/-0.003) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.610 (+/-0.005) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.615 (+/-0.004) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.001) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.667 (+/-0.009) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.639 (+/-0.008) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.633 (+/-0.016) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.624 (+/-0.017) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.614 (+/-0.010) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.617 (+/-0.019) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.629 (+/-0.043) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.640 (+/-0.010) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.634 (+/-0.010) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.635 (+/-0.022) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.632 (+/-0.027) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.630 (+/-0.031) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.613 (+/-0.009) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.614 (+/-0.009) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.610 (+/-0.001) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.614 (+/-0.019) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.618 (+/-0.010) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.606 (+/-0.005) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.613 (+/-0.014) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.644 (+/-0.006) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.631 (+/-0.032) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.652 (+/-0.039) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.620 (+/-0.012) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.612 (+/-0.008) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.624 (+/-0.029) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.617 (+/-0.009) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.631 (+/-0.049) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.611 (+/-0.011) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.003) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.664 (+/-0.024) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.642 (+/-0.020) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.650 (+/-0.026) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.638 (+/-0.038) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.614 (+/-0.011) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.618 (+/-0.011) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.609 (+/-0.002) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.612 (+/-0.006) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.612 (+/-0.009) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.612 (+/-0.007) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.612 (+/-0.006) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.609 (+/-0.001) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.642 (+/-0.013) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.643 (+/-0.051) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.627 (+/-0.013) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.639 (+/-0.017) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.641 (+/-0.047) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.623 (+/-0.020) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.618 (+/-0.021) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.613 (+/-0.014) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.619 (+/-0.015) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.622 (+/-0.035) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.660 (+/-0.019) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.648 (+/-0.018) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.644 (+/-0.042) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.631 (+/-0.028) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.631 (+/-0.037) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.610 (+/-0.003) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.612 (+/-0.003) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.610 (+/-0.004) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.614 (+/-0.008) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.607 (+/-0.003) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.616 (+/-0.011) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.609 (+/-0.002) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.610 (+/-0.004) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.609 (+/-0.002) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'gini', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.610 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.609 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.612 (+/-0.005) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.610 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.610 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.611 (+/-0.006) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.609 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.609 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.609 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 1, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.613 (+/-0.005) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.623 (+/-0.020) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.617 (+/-0.019) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.616 (+/-0.022) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.610 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.610 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.613 (+/-0.006) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.621 (+/-0.037) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.619 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.614 (+/-0.005) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.611 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.611 (+/-0.011) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.617 (+/-0.017) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.611 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.607 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.616 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.614 (+/-0.016) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 6, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.613 (+/-0.017) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.617 (+/-0.008) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.612 (+/-0.006) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.621 (+/-0.013) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.620 (+/-0.008) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.615 (+/-0.025) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.621 (+/-0.027) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.615 (+/-0.021) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.620 (+/-0.021) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.614 (+/-0.009) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.616 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.614 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.610 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.611 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.616 (+/-0.009) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.616 (+/-0.014) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.611 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.613 (+/-0.011) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.609 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.613 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.607 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.609 (+/-0.005) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.623 (+/-0.013) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.623 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.615 (+/-0.015) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.613 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.615 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.622 (+/-0.041) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.620 (+/-0.018) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.623 (+/-0.037) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.611 (+/-0.006) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.613 (+/-0.013) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.628 (+/-0.013) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.626 (+/-0.020) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.617 (+/-0.028) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.617 (+/-0.011) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.612 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.616 (+/-0.022) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.615 (+/-0.013) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.619 (+/-0.029) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.609 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.610 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.609 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 16, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.624 (+/-0.005) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.630 (+/-0.016) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.623 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.619 (+/-0.011) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.621 (+/-0.022) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.615 (+/-0.018) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.612 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.609 (+/-0.005) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.612 (+/-0.006) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.628 (+/-0.024) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.623 (+/-0.015) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.620 (+/-0.008) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.638 (+/-0.033) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.628 (+/-0.014) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.616 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.617 (+/-0.013) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.609 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.609 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.611 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.609 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 21, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.626 (+/-0.022) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.632 (+/-0.024) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.635 (+/-0.016) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.634 (+/-0.038) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.626 (+/-0.028) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.617 (+/-0.016) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.610 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.609 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.626 (+/-0.027) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.645 (+/-0.030) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.625 (+/-0.008) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.627 (+/-0.009) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.622 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.612 (+/-0.005) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.616 (+/-0.022) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.610 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.609 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.628 (+/-0.040) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.614 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.609 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 26, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.633 (+/-0.020) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.644 (+/-0.032) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.652 (+/-0.036) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.619 (+/-0.023) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.625 (+/-0.024) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.627 (+/-0.016) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.610 (+/-0.006) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.606 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.613 (+/-0.008) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.632 (+/-0.029) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.644 (+/-0.033) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.640 (+/-0.026) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.632 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.626 (+/-0.016) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.631 (+/-0.033) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.614 (+/-0.011) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.611 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.612 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.610 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.607 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 31, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.649 (+/-0.027) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.650 (+/-0.038) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.626 (+/-0.021) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.629 (+/-0.057) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.618 (+/-0.019) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.610 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.614 (+/-0.008) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.610 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.619 (+/-0.024) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.661 (+/-0.020) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.644 (+/-0.035) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.626 (+/-0.013) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.620 (+/-0.026) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.611 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.619 (+/-0.006) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.617 (+/-0.020) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.008) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.609 (+/-0.008) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.614 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 36, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.641 (+/-0.014) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.631 (+/-0.032) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.648 (+/-0.031) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.625 (+/-0.034) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.609 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.617 (+/-0.014) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.612 (+/-0.009) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.610 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.615 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.610 (+/-0.009) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.661 (+/-0.018) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.636 (+/-0.015) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.659 (+/-0.020) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.618 (+/-0.014) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.619 (+/-0.022) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.626 (+/-0.035) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.613 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.615 (+/-0.015) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.609 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.612 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.621 (+/-0.018) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.609 (+/-0.002) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 41, 'max_features': 'log2', 'min_samples_leaf': 46}\n",
      "0.640 (+/-0.027) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 1}\n",
      "0.648 (+/-0.021) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 6}\n",
      "0.642 (+/-0.012) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 11}\n",
      "0.642 (+/-0.030) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 16}\n",
      "0.615 (+/-0.013) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 21}\n",
      "0.610 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 26}\n",
      "0.607 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 31}\n",
      "0.610 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 36}\n",
      "0.609 (+/-0.003) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 41}\n",
      "0.616 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'auto', 'min_samples_leaf': 46}\n",
      "0.663 (+/-0.026) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 1}\n",
      "0.643 (+/-0.049) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 6}\n",
      "0.652 (+/-0.036) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 11}\n",
      "0.632 (+/-0.051) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 16}\n",
      "0.632 (+/-0.049) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 21}\n",
      "0.628 (+/-0.031) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 26}\n",
      "0.611 (+/-0.007) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 31}\n",
      "0.614 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 36}\n",
      "0.615 (+/-0.010) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 41}\n",
      "0.611 (+/-0.008) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'sqrt', 'min_samples_leaf': 46}\n",
      "0.617 (+/-0.004) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 1}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 6}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 11}\n",
      "0.609 (+/-0.001) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 16}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 21}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 26}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 31}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 36}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 41}\n",
      "0.608 (+/-0.000) for {'criterion': 'entropy', 'max_depth': 46, 'max_features': 'log2', 'min_samples_leaf': 46}\n"
     ]
    }
   ],
   "source": [
    "# All results\n",
    "means = gridSearchDTC.cv_results_['mean_test_score']\n",
    "stds = gridSearchDTC.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearchDTC.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the results of the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3399,  263],\n",
       "       [1887,  452]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelDTC = DecisionTreeClassifier(criterion= 'gini', max_depth= 36, max_features= 'auto', min_samples_leaf= 1)\n",
    "modelDTC.fit(x_train, y_train)\n",
    "y_pred = modelDTC.predict(x_test)\n",
    "conf_matrix_clf = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76      3662\n",
      "           1       0.63      0.19      0.30      2339\n",
      "\n",
      "    accuracy                           0.64      6001\n",
      "   macro avg       0.64      0.56      0.53      6001\n",
      "weighted avg       0.64      0.64      0.58      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate the average performance of our model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Precision : 0.7017626489068813\n",
      "Avg Precision : 0.6712162751195216\n"
     ]
    }
   ],
   "source": [
    "# Calcul real efficient of the model\n",
    "def functionRealPerf(numberRun):\n",
    "    listPrecision= []\n",
    "    for i in range(numberRun):\n",
    "        modelDTC = DecisionTreeClassifier(criterion= 'gini', max_depth= 36, max_features= 'auto', min_samples_leaf= 1)\n",
    "        modelDTC.fit(x_train, y_train)\n",
    "        y_pred = modelDTC.predict(x_test)\n",
    "        cr = classification_report(y_test,y_pred,digits=10,output_dict=True)\n",
    "        listPrecision.append((cr['0']['precision']+cr['1']['precision'])/2)\n",
    "    print(\"Max Precision : \" + str(max(listPrecision)))\n",
    "    print(\"Avg Precision : \" + str(sum(listPrecision)/numberRun))\n",
    "functionRealPerf(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3344,  318],\n",
       "       [ 268, 2071]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRFC = RandomForestClassifier()\n",
    "modelRFC.fit(x_train,y_train)\n",
    "y_pred = modelRFC.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.91      0.92      3662\n",
      "          1       0.87      0.89      0.88      2339\n",
      "\n",
      "avg / total       0.90      0.90      0.90      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the last time we are going to look for the most optimal hyperparameters to maximize the performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we're using RandomizedSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 13.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 300,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_depth': 30}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best estimator : the best hyperparameters\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5, 8, 15, 25, 30]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "random_grid = dict(n_estimators = n_estimators, \n",
    "              max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "              min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1)\n",
    "rf_random.fit(x_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3647,   15],\n",
       "       [2092,  247]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRFCRandom = RandomForestClassifier(min_samples_split= 5, min_samples_leaf= 1, n_estimators= 300, max_depth= 30)\n",
    "modelRFCRandom.fit(x_train, y_train)\n",
    "y_pred = modelRFCRandom.predict(x_test)\n",
    "conf_matrix_clf = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      1.00      0.78      3662\n",
      "          1       0.94      0.11      0.19      2339\n",
      "\n",
      "avg / total       0.76      0.65      0.55      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "crr = classification_report(y_test,y_pred)\n",
    "print(crr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're not satisfied by the results so we're using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_features': ['auto', 'sqrt', 'log2'],\n",
       "                         'min_samples_leaf': [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                              46],\n",
       "                         'n_estimators': [1, 6, 11, 16, 21, 26, 31, 36, 41,\n",
       "                                          46]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRFC = RandomForestClassifier()\n",
    "parameter_space = {'max_features':[\"auto\", \"sqrt\", \"log2\"],\n",
    "                  'min_samples_leaf':[ i for i in range(1,50,5)],\n",
    "                  'n_estimators' : [ i for i in range(1,50,5)]}\n",
    "gridSearchRFC = GridSearchCV(modelRFC, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearchRFC.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 41}\n"
     ]
    }
   ],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', gridSearchRFC.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.760 (+/-0.007) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 1}\n",
      "0.829 (+/-0.004) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 6}\n",
      "0.847 (+/-0.008) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 11}\n",
      "0.851 (+/-0.014) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 16}\n",
      "0.855 (+/-0.011) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 21}\n",
      "0.857 (+/-0.012) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 26}\n",
      "0.860 (+/-0.010) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 31}\n",
      "0.862 (+/-0.007) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 36}\n",
      "0.860 (+/-0.012) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 41}\n",
      "0.859 (+/-0.006) for {'max_features': 'auto', 'min_samples_leaf': 1, 'n_estimators': 46}\n",
      "0.664 (+/-0.030) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 1}\n",
      "0.695 (+/-0.018) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 6}\n",
      "0.710 (+/-0.014) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 11}\n",
      "0.709 (+/-0.035) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 16}\n",
      "0.711 (+/-0.017) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 21}\n",
      "0.712 (+/-0.032) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 26}\n",
      "0.715 (+/-0.023) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 31}\n",
      "0.715 (+/-0.016) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 36}\n",
      "0.716 (+/-0.024) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 41}\n",
      "0.720 (+/-0.023) for {'max_features': 'auto', 'min_samples_leaf': 6, 'n_estimators': 46}\n",
      "0.639 (+/-0.040) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 1}\n",
      "0.643 (+/-0.013) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 6}\n",
      "0.631 (+/-0.020) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 11}\n",
      "0.628 (+/-0.017) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 16}\n",
      "0.624 (+/-0.015) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 21}\n",
      "0.632 (+/-0.008) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 26}\n",
      "0.626 (+/-0.012) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 31}\n",
      "0.623 (+/-0.011) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 36}\n",
      "0.626 (+/-0.012) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 41}\n",
      "0.627 (+/-0.020) for {'max_features': 'auto', 'min_samples_leaf': 11, 'n_estimators': 46}\n",
      "0.618 (+/-0.020) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 1}\n",
      "0.621 (+/-0.027) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 6}\n",
      "0.612 (+/-0.005) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 11}\n",
      "0.609 (+/-0.001) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 16}\n",
      "0.609 (+/-0.001) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 21}\n",
      "0.609 (+/-0.002) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 26}\n",
      "0.609 (+/-0.001) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 36}\n",
      "0.609 (+/-0.001) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 41}\n",
      "0.609 (+/-0.001) for {'max_features': 'auto', 'min_samples_leaf': 16, 'n_estimators': 46}\n",
      "0.613 (+/-0.015) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 1}\n",
      "0.611 (+/-0.004) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 6}\n",
      "0.611 (+/-0.006) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 21}\n",
      "0.609 (+/-0.001) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 21, 'n_estimators': 46}\n",
      "0.608 (+/-0.002) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 26, 'n_estimators': 46}\n",
      "0.610 (+/-0.002) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 31, 'n_estimators': 46}\n",
      "0.607 (+/-0.004) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 36, 'n_estimators': 46}\n",
      "0.613 (+/-0.018) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 41, 'n_estimators': 46}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'auto', 'min_samples_leaf': 46, 'n_estimators': 46}\n",
      "0.759 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 1}\n",
      "0.830 (+/-0.004) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 6}\n",
      "0.843 (+/-0.013) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 11}\n",
      "0.852 (+/-0.008) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 16}\n",
      "0.855 (+/-0.008) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 21}\n",
      "0.859 (+/-0.010) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 26}\n",
      "0.858 (+/-0.006) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 31}\n",
      "0.860 (+/-0.006) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 36}\n",
      "0.859 (+/-0.013) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 41}\n",
      "0.860 (+/-0.011) for {'max_features': 'sqrt', 'min_samples_leaf': 1, 'n_estimators': 46}\n",
      "0.674 (+/-0.029) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 1}\n",
      "0.699 (+/-0.018) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 6}\n",
      "0.704 (+/-0.034) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 11}\n",
      "0.711 (+/-0.022) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 16}\n",
      "0.712 (+/-0.011) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 21}\n",
      "0.715 (+/-0.020) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 26}\n",
      "0.710 (+/-0.017) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 31}\n",
      "0.718 (+/-0.020) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 36}\n",
      "0.717 (+/-0.018) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 41}\n",
      "0.714 (+/-0.018) for {'max_features': 'sqrt', 'min_samples_leaf': 6, 'n_estimators': 46}\n",
      "0.632 (+/-0.025) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 1}\n",
      "0.642 (+/-0.040) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 6}\n",
      "0.632 (+/-0.015) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 11}\n",
      "0.633 (+/-0.011) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 16}\n",
      "0.635 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 21}\n",
      "0.632 (+/-0.014) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 26}\n",
      "0.631 (+/-0.003) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 31}\n",
      "0.626 (+/-0.017) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 36}\n",
      "0.618 (+/-0.004) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 41}\n",
      "0.626 (+/-0.008) for {'max_features': 'sqrt', 'min_samples_leaf': 11, 'n_estimators': 46}\n",
      "0.629 (+/-0.022) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 1}\n",
      "0.618 (+/-0.013) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 6}\n",
      "0.615 (+/-0.004) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 11}\n",
      "0.611 (+/-0.004) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 16}\n",
      "0.610 (+/-0.003) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 21}\n",
      "0.609 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 26}\n",
      "0.609 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 31}\n",
      "0.609 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 36}\n",
      "0.609 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 41}\n",
      "0.609 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 16, 'n_estimators': 46}\n",
      "0.616 (+/-0.009) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 1}\n",
      "0.610 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 6}\n",
      "0.608 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 11}\n",
      "0.609 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 21, 'n_estimators': 46}\n",
      "0.611 (+/-0.009) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 1}\n",
      "0.608 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 26, 'n_estimators': 46}\n",
      "0.610 (+/-0.004) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 1}\n",
      "0.609 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 6}\n",
      "0.609 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 31, 'n_estimators': 46}\n",
      "0.614 (+/-0.011) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 1}\n",
      "0.608 (+/-0.001) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 36, 'n_estimators': 46}\n",
      "0.612 (+/-0.006) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 41, 'n_estimators': 46}\n",
      "0.616 (+/-0.014) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'sqrt', 'min_samples_leaf': 46, 'n_estimators': 46}\n",
      "0.748 (+/-0.005) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 1}\n",
      "0.831 (+/-0.008) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 6}\n",
      "0.852 (+/-0.006) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 11}\n",
      "0.857 (+/-0.004) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 16}\n",
      "0.864 (+/-0.010) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 21}\n",
      "0.868 (+/-0.008) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 26}\n",
      "0.867 (+/-0.005) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 31}\n",
      "0.871 (+/-0.007) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 36}\n",
      "0.871 (+/-0.008) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 41}\n",
      "0.871 (+/-0.006) for {'max_features': 'log2', 'min_samples_leaf': 1, 'n_estimators': 46}\n",
      "0.609 (+/-0.001) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 1}\n",
      "0.609 (+/-0.002) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 6, 'n_estimators': 46}\n",
      "0.607 (+/-0.003) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 11, 'n_estimators': 46}\n",
      "0.613 (+/-0.013) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 16, 'n_estimators': 46}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 21, 'n_estimators': 46}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 26, 'n_estimators': 46}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 31, 'n_estimators': 46}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 36, 'n_estimators': 46}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 41, 'n_estimators': 46}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 1}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 6}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 11}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 16}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 21}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 26}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 31}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 36}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 41}\n",
      "0.608 (+/-0.000) for {'max_features': 'log2', 'min_samples_leaf': 46, 'n_estimators': 46}\n"
     ]
    }
   ],
   "source": [
    "# All results\n",
    "means = gridSearchRFC.cv_results_['mean_test_score']\n",
    "stds = gridSearchRFC.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearchRFC.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the results of the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3472,  190],\n",
       "       [ 253, 2086]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRFC = RandomForestClassifier(max_features= 'log2', min_samples_leaf= 1, n_estimators= 41)\n",
    "modelRFC.fit(x_train, y_train)\n",
    "y_pred = modelRFC.predict(x_test)\n",
    "conf_matrix_clf = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94      3662\n",
      "           1       0.92      0.89      0.90      2339\n",
      "\n",
      "    accuracy                           0.93      6001\n",
      "   macro avg       0.92      0.92      0.92      6001\n",
      "weighted avg       0.93      0.93      0.93      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now calculate the average performance of our model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Precision : 0.9291090128309425\n",
      "Avg Precision : 0.9248698052426377\n"
     ]
    }
   ],
   "source": [
    "# Calcul real efficient of the model\n",
    "def functionRealPerf(numberRun):\n",
    "    listPrecision= []\n",
    "    for i in range(numberRun):\n",
    "        modelRFC = RandomForestClassifier(max_features= 'log2', min_samples_leaf= 1, n_estimators= 41)\n",
    "        modelRFC.fit(x_train, y_train)\n",
    "        y_pred = modelRFC.predict(x_test)\n",
    "        cr = classification_report(y_test,y_pred,digits=10,output_dict=True)\n",
    "        listPrecision.append((cr['0']['precision']+cr['1']['precision'])/2)\n",
    "    print(\"Max Precision : \" + str(max(listPrecision)))\n",
    "    print(\"Avg Precision : \" + str(sum(listPrecision)/numberRun))\n",
    "functionRealPerf(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
