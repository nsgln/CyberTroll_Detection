{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PRE TREATMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing all our **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "## Actually uses\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "## Actually not uses \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mpl_toolkits import mplot3d\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "DATA_PATH = os.path.join(\"./data\")\n",
    "DATA_NAME_CSV = \"CyberTroll.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of our data and transformation into DataFrame with **pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the .csv file into a DataFrame\n",
    "def load_data(data_path=DATA_PATH,data_name_csv=DATA_NAME_CSV):\n",
    "        # Path to file mushrooms.csv\n",
    "        csv_path = os.path.join(data_path,data_name_csv)\n",
    "        # Object DATA_FRAME\n",
    "        return pd.read_csv(csv_path)\n",
    "\n",
    "# execution\n",
    "data_frame = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what this data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation/notes</th>\n",
       "      <th>annotation/label/0</th>\n",
       "      <th>extras</th>\n",
       "      <th>metadata/first_done_at</th>\n",
       "      <th>metadata/last_updated_at</th>\n",
       "      <th>metadata/sec_taken</th>\n",
       "      <th>metadata/last_updated_by</th>\n",
       "      <th>metadata/status</th>\n",
       "      <th>metadata/evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  annotation/notes  \\\n",
       "0                             Get fucking real dude.               NaN   \n",
       "1  She is as dirty as they come  and that crook R...               NaN   \n",
       "2  why did you fuck it up. I could do it all day ...               NaN   \n",
       "3  Dude they dont finish enclosing the fucking sh...               NaN   \n",
       "4  WTF are you talking about Men? No men thats no...               NaN   \n",
       "\n",
       "   annotation/label/0  extras  metadata/first_done_at  \\\n",
       "0                   1     NaN           1527503426000   \n",
       "1                   1     NaN           1527503426000   \n",
       "2                   1     NaN           1527503426000   \n",
       "3                   1     NaN           1527503426000   \n",
       "4                   1     NaN           1527503426000   \n",
       "\n",
       "   metadata/last_updated_at  metadata/sec_taken      metadata/last_updated_by  \\\n",
       "0             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "1             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "2             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "3             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "4             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "\n",
       "  metadata/status metadata/evaluation  \n",
       "0            done                NONE  \n",
       "1            done                NONE  \n",
       "2            done                NONE  \n",
       "3            done                NONE  \n",
       "4            done                NONE  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check of the quantity of samples and the diversity of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation/notes</th>\n",
       "      <th>annotation/label/0</th>\n",
       "      <th>extras</th>\n",
       "      <th>metadata/first_done_at</th>\n",
       "      <th>metadata/last_updated_at</th>\n",
       "      <th>metadata/sec_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>20001.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000100e+04</td>\n",
       "      <td>2.000100e+04</td>\n",
       "      <td>20001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.717817e+04</td>\n",
       "      <td>2.717817e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527504e+12</td>\n",
       "      <td>1.527504e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotation/notes  annotation/label/0  extras  metadata/first_done_at  \\\n",
       "count               0.0        20001.000000     0.0            2.000100e+04   \n",
       "mean                NaN            0.391080     NaN            1.527503e+12   \n",
       "std                 NaN            0.488005     NaN            2.717817e+04   \n",
       "min                 NaN            0.000000     NaN            1.527503e+12   \n",
       "25%                 NaN            0.000000     NaN            1.527503e+12   \n",
       "50%                 NaN            0.000000     NaN            1.527503e+12   \n",
       "75%                 NaN            1.000000     NaN            1.527503e+12   \n",
       "max                 NaN            1.000000     NaN            1.527504e+12   \n",
       "\n",
       "       metadata/last_updated_at  metadata/sec_taken  \n",
       "count              2.000100e+04             20001.0  \n",
       "mean               1.527503e+12                 0.0  \n",
       "std                2.717817e+04                 0.0  \n",
       "min                1.527503e+12                 0.0  \n",
       "25%                1.527503e+12                 0.0  \n",
       "50%                1.527503e+12                 0.0  \n",
       "75%                1.527503e+12                 0.0  \n",
       "max                1.527504e+12                 0.0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is a null value and all the indexes we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content                         0\n",
       "annotation/notes            20001\n",
       "annotation/label/0              0\n",
       "extras                      20001\n",
       "metadata/first_done_at          0\n",
       "metadata/last_updated_at        0\n",
       "metadata/sec_taken              0\n",
       "metadata/last_updated_by        0\n",
       "metadata/status                 0\n",
       "metadata/evaluation             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**annotation/notes**,**extras** is composed of null values so its implication in a classification algorithm is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['annotation/notes','extras'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at all the unique choices we have in all indexes, if there is an index that always has the same value we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content : ['Get fucking real dude.'\n",
      " \"She is as dirty as they come  and that crook Rengel  the Dems are so fucking corrupt it's a joke. Make Republicans look like  ...\"\n",
      " \"why did you fuck it up. I could do it all day too. Let's do it when you have an hour. Ping me later to sched writing a book here.\"\n",
      " ... 'hahahahaha >:) im evil mwahahahahahahahahaha'\n",
      " 'What&;s something unique about Ohio? :)'\n",
      " 'Who is the biggest gossiper you know?']\n",
      "annotation/label/0 : [1 0]\n",
      "metadata/first_done_at : [1527503426000 1527503427000 1527503428000 1527503429000 1527503430000\n",
      " 1527503431000 1527503432000 1527503433000 1527503434000 1527503435000\n",
      " 1527503436000 1527503437000 1527503438000 1527503439000 1527503440000\n",
      " 1527503441000 1527503442000 1527503443000 1527503444000 1527503445000\n",
      " 1527503446000 1527503447000 1527503448000 1527503449000 1527503450000\n",
      " 1527503451000 1527503452000 1527503453000 1527503454000 1527503455000\n",
      " 1527503456000 1527503457000 1527503458000 1527503459000 1527503460000\n",
      " 1527503461000 1527503462000 1527503463000 1527503464000 1527503465000\n",
      " 1527503466000 1527503467000 1527503468000 1527503469000 1527503470000\n",
      " 1527503471000 1527503472000 1527503473000 1527503474000 1527503475000\n",
      " 1527503476000 1527503477000 1527503478000 1527503479000 1527503480000\n",
      " 1527503481000 1527503482000 1527503483000 1527503484000 1527503485000\n",
      " 1527503486000 1527503487000 1527503488000 1527503489000 1527503490000\n",
      " 1527503491000 1527503492000 1527503493000 1527503494000 1527503495000\n",
      " 1527503496000 1527503497000 1527503498000 1527503499000 1527503500000\n",
      " 1527503501000 1527503502000 1527503503000 1527503504000 1527503505000\n",
      " 1527503506000 1527503507000 1527503508000 1527503509000 1527503510000\n",
      " 1527503511000 1527503512000 1527503513000 1527503514000 1527503515000\n",
      " 1527503516000 1527503517000 1527503518000 1527503519000]\n",
      "metadata/last_updated_at : [1527503426000 1527503427000 1527503428000 1527503429000 1527503430000\n",
      " 1527503431000 1527503432000 1527503433000 1527503434000 1527503435000\n",
      " 1527503436000 1527503437000 1527503438000 1527503439000 1527503440000\n",
      " 1527503441000 1527503442000 1527503443000 1527503444000 1527503445000\n",
      " 1527503446000 1527503447000 1527503448000 1527503449000 1527503450000\n",
      " 1527503451000 1527503452000 1527503453000 1527503454000 1527503455000\n",
      " 1527503456000 1527503457000 1527503458000 1527503459000 1527503460000\n",
      " 1527503461000 1527503462000 1527503463000 1527503464000 1527503465000\n",
      " 1527503466000 1527503467000 1527503468000 1527503469000 1527503470000\n",
      " 1527503471000 1527503472000 1527503473000 1527503474000 1527503475000\n",
      " 1527503476000 1527503477000 1527503478000 1527503479000 1527503480000\n",
      " 1527503481000 1527503482000 1527503483000 1527503484000 1527503485000\n",
      " 1527503486000 1527503487000 1527503488000 1527503489000 1527503490000\n",
      " 1527503491000 1527503492000 1527503493000 1527503494000 1527503495000\n",
      " 1527503496000 1527503497000 1527503498000 1527503499000 1527503500000\n",
      " 1527503501000 1527503502000 1527503503000 1527503504000 1527503505000\n",
      " 1527503506000 1527503507000 1527503508000 1527503509000 1527503510000\n",
      " 1527503511000 1527503512000 1527503513000 1527503514000 1527503515000\n",
      " 1527503516000 1527503517000 1527503518000 1527503519000]\n",
      "metadata/sec_taken : [0]\n",
      "metadata/last_updated_by : ['jI67aE5hwwdh6l16bcfFVnpyREd2']\n",
      "metadata/status : ['done']\n",
      "metadata/evaluation : ['NONE']\n"
     ]
    }
   ],
   "source": [
    "for index in data_frame.columns:\n",
    "        print(str(index) + \" : \" + str(data_frame[index].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata/sec_taken**,**metadata/last_updated_by**,**metadata/status**,**metadata/evaluation** is composed of a single variable so its implication in a classification algorithm is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['metadata/sec_taken','metadata/last_updated_by','metadata/status','metadata/evaluation'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata/last_updated_at**,**metadata/first_done_at** is composed of timestamp so it's implication in not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['metadata/last_updated_at','metadata/first_done_at'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation/label/0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She is as dirty as they come  and that crook R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why did you fuck it up. I could do it all day ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dude they dont finish enclosing the fucking sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTF are you talking about Men? No men thats no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  annotation/label/0\n",
       "0                             Get fucking real dude.                   1\n",
       "1  She is as dirty as they come  and that crook R...                   1\n",
       "2  why did you fuck it up. I could do it all day ...                   1\n",
       "3  Dude they dont finish enclosing the fucking sh...                   1\n",
       "4  WTF are you talking about Men? No men thats no...                   1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns for easier use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.rename(columns={\"content\" : \"sentence\",\"annotation/label/0\" :\"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text may contain numbers, special characters, and unwanted spaces. We will remove all the special characters, numbers, and unwanted spaces from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer \n",
    "stemmer = WordNetLemmatizer()\n",
    "# Function to apply on our sentence\n",
    "def converterSentence(text):\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # remove all single characters\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # Converting to Lowercase\n",
    "    text = text.lower()\n",
    "    # Lemmatization\n",
    "    text = text.split()\n",
    "    text = [stemmer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    get fucking real dude\n",
       "1        she is a dirty a they come and that crook reng...\n",
       "2        why did you fuck it up could do it all day too...\n",
       "3        dude they dont finish enclosing the fucking sh...\n",
       "4        wtf are you talking about men no men thats not...\n",
       "5        ill save you the trouble sister here come big ...\n",
       "6        im dead serious real athlete never cheat don e...\n",
       "7        go absolutely insane hate to be the bearer of ...\n",
       "8        lmao im watching the same thing ahaha the gay ...\n",
       "9        lol no he said what do you call jail cell to g...\n",
       "10       truth on both count that guy is an as and thei...\n",
       "11                                        shakespeare nerd\n",
       "12                               you are such fucking dork\n",
       "13                                       heh fuck em where\n",
       "14                         damn it totally forgot that one\n",
       "15                    wow damn would have been pissed that\n",
       "16               nigga geigh lmao fuck yo final beeeeeitch\n",
       "17                                               that suck\n",
       "18       read that this morning my fav is how they just...\n",
       "19                  unibroue 17 another damn good unibroue\n",
       "20       damn your evil 60 minute ipa beckoning me from...\n",
       "21       it did then my fucking dad turned it off just ...\n",
       "22                         it pretty much is fuck you card\n",
       "23                                 that karma is bitch huh\n",
       "24              don get too fat or you ll turn into boomer\n",
       "25       the hormone are worse for guy cant tell you ho...\n",
       "26       except for joe jonas the as munch who broke up...\n",
       "27       man that rly suck for 1 am positive that all w...\n",
       "28          hard to kick as yourself with slipper on on it\n",
       "29       thats pretty damn awesome very smart aaronage ...\n",
       "                               ...                        \n",
       "19971                      not really when first meet them\n",
       "19972                           lykee ohhemmgee hiii mikey\n",
       "19973             are you picky about spelling and grammar\n",
       "19974              popcorn twizzlers and some mike and ike\n",
       "19975    ohhh well didnt know you were doing that you k...\n",
       "19976            do you wish someone wa with you right now\n",
       "19977                                        kohl actually\n",
       "19978       yes but we end up warped in the end either way\n",
       "19979                                entertainingly cheesy\n",
       "19980             do you think you apos re hot and or sexy\n",
       "19981                                               repeat\n",
       "19982    cannot listen to that heavy metal like me some...\n",
       "19983                    do no alix sister ha cruch on you\n",
       "19984                                               repeat\n",
       "19985                                          hey who diz\n",
       "19986    aint da one dat said da tampon thang but added...\n",
       "19987                       how many language do you speak\n",
       "19988                               lol no idnt iguess bih\n",
       "19989     sometimes did that lot when wa sick this past wk\n",
       "19990                                   you ll neverr know\n",
       "19991                                     hold im confused\n",
       "19992                                    wouldnt catch one\n",
       "19993    haha nahh ive just fractured some thumb bhut i...\n",
       "19994             did we have any class together this year\n",
       "19995                       havent gotten 2 that part haha\n",
       "19996    dont but what is complaining about it going to do\n",
       "19997    bahah yeah totally just gonna get pissed at yo...\n",
       "19998             hahahahaha im evil mwahahahahahahahahaha\n",
       "19999                     what something unique about ohio\n",
       "20000                 who is the biggest gossiper you know\n",
       "Name: sentence, Length: 20001, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['sentence']= data_frame.sentence.apply(converterSentence)\n",
    "data_frame.sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different approaches exist to convert text into the corresponding numerical form. But we are going to use Bag of Words Model because it is the most efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default Vectorizer & Default model to have a first overview of the result** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data_frame.sentence)\n",
    "Y = data_frame.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag of words approach works fine for converting text to numbers. However, it has one drawback. It assigns a score to a word based on its occurrence in a particular document. It doesn't take into account the fact that the word might also be having a high frequency of occurrence in other documents as well. TFIDF resolves this issue by multiplying the term frequency of a word by the inverse document frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "classifier.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.91      0.93      2429\n",
      "          1       0.87      0.93      0.90      1572\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_rdtree = classifier.predict(x_test)\n",
    "print(classification_report(y_test,y_pred_rdtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtain the following confusion matrix : \n",
      " [[2216  213]\n",
      " [ 103 1469]]\n"
     ]
    }
   ],
   "source": [
    "confusion_rdtree = confusion_matrix(y_test, y_pred_rdtree)\n",
    "print(\"We obtain the following confusion matrix : \\n\", confusion_rdtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using RandomizedSearchCV in order to optimize by cross-validated search the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 14.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 800,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_depth': 30}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best estimator : the best hyperparameters\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5, 8, 15, 25, 30]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "random_grid = dict(n_estimators = n_estimators, \n",
    "              max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "              min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1)\n",
    "rf_random.fit(x_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to  plot the validation curve to find the best value for the n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_scores, test_scores = validation_curve(\n",
    "#                                 RandomForestClassifier(),\n",
    "#                                 X = x_train, y = y_train, \n",
    "#                                 param_name = 'n_estimators', \n",
    "#                                 param_range = [100, 300, 500, 750, 800, 1200], cv = 3)\n",
    "\n",
    "# param_range = np.logspace(-6, -1, 5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.title(\"Validation Curve for Random Forest\")\n",
    "# plt.xlabel(\"Values of Hyperparameter n_estimators\")\n",
    "# plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "# plt.plot(param_range, train_scores_mean, label=\"Training scores\")\n",
    "# plt.plot(param_range, test_scores_mean, label=\"Cross-Validation Score\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to find parameters for the vectorizer which could impact the model. But the sentences being too small the min_df and max_df parameters are useless here. We still just tried to vary the number of features but that did not affect the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_MIN_DEF= [x/100 for x in range(1,50,5)]\n",
    "LIST_MAX_DEF= [x for x in range(90,100)]\n",
    "LIST_MAX_DEF.reverse()\n",
    "LIST_MAX_FEATURES = [x for x in range(100,2000,50)]\n",
    "def customVectorizer(listMinDef=LIST_MIN_DEF,listMaxDef=LIST_MAX_DEF,listMaxFeatures=LIST_MAX_FEATURES):\n",
    "    listVectorizer = []\n",
    "    for maxFeatures in listMaxFeatures:\n",
    "        listVectorizer.append(CountVectorizer(stop_words='english',max_features=maxFeatures))  \n",
    "    return listVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the result of this function in a file located in the data folder, just for information there is just marked the same for each variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary vectorizer parameters to see if it impacts the default Random Forest model\n",
    "def ImpactOfVectorizer():\n",
    "    fichier = open(\"data/dataRFCDefaultCustomVectorizer.txt\", \"a\")\n",
    "    for vecto in customVectorizer():\n",
    "        vectorizer = vecto\n",
    "        X = vectorizer.fit_transform(data_frame.sentence)\n",
    "        Y = data_frame.label\n",
    "        tfidfconverter = TfidfTransformer()\n",
    "        X = tfidfconverter.fit_transform(X)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "        # Simple Random Forest Classifier\n",
    "        classifier = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "        classifier.fit(x_train, y_train) \n",
    "        crboost = classification_report(y_test,y_pred,digits=10,output_dict=True)\n",
    "        fichier.write(str(crboost['0']['precision'])+\" \" +str(crboost['1']['precision'])+\"\\n\")\n",
    "    fichier.close()\n",
    "# The famous line that saves you 5 s               \n",
    "# ImpactOfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result :\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The answer to the question “What machine learning model should I use?” is always “It depends.” Even the most experienced data scientists can’t tell which algorithm will perform best before experimenting them.\"\n",
    "\n",
    "In order to find the optimum model, we tried to make as many models as possible to know which would be the best. Here are the 6 models that were made.\n",
    "\n",
    "MLPClassifier, DecisionTreeClassifier, RandomForestClassifier, KNeighborsClassifier, LogisticRegression and finally SVM (Support Vector Machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these trains and tests for all our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data_frame.sentence)\n",
    "Y = data_frame.label\n",
    "# TFID\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)\n",
    "# SPLIT\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model aims to optimize the log-loss function using LBGFGS or stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the default neural network (45 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMLP = MLPClassifier()\n",
    "modelMLP.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the trained network to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = modelMLP.predict(x_test)\n",
    "modelMLP.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2892,  770],\n",
       "       [ 202, 2137]], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.79      0.86      3662\n",
      "          1       0.74      0.91      0.81      2339\n",
      "\n",
      "avg / total       0.86      0.84      0.84      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to find more optimal parameters, with the magic GridSearchCV multi-threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A EXECUTER A PARTIR D'ICI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMLP = MLPClassifier()\n",
    "parameter_space = {'activation': ['logistic','tanh', 'relu'],\n",
    "                  'hidden_layer_sizes':[i for i in range(1,220,20)],\n",
    "                  'alpha':[0.0001,0.001,0.01,0.1,1],\n",
    "                  'max_iter':[50, 100, 150, 200]}\n",
    "gridSearch = GridSearchCV(modelMLP, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters set\n",
    "print('Best parameters found:\\n', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All results\n",
    "means = gridSearch.cv_results_['mean_test_score']\n",
    "stds = gridSearch.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearch.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STOP EXECUTION ICI**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classification is used in statistics to model the probability of a certain class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the default one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchouka/ml/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = modelLR.predict(x_test)\n",
    "modelLR.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3204,  458],\n",
       "       [ 982, 1357]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82      3662\n",
      "           1       0.75      0.58      0.65      2339\n",
      "\n",
      "    accuracy                           0.76      6001\n",
      "   macro avg       0.76      0.73      0.73      6001\n",
      "weighted avg       0.76      0.76      0.75      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to add hyperparameter to get a better accuracy.\n",
    "\n",
    "For this one, 4 hyperparameters : C, penality, max_iter and tol.(10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tchouka/ml/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/home/tchouka/ml/env/lib/python3.6/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='warn',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='warn',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'max_iter': [50, 100, 150, 200],\n",
       "                         'penalty': ['l1', 'l2'],\n",
       "                         'tol': [1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLR = LogisticRegression()\n",
    "parameter_space = {'penalty': ['l1','l2'],\n",
    "                  'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'max_iter':[50, 100, 150, 200],\n",
    "                  'tol':[0.00001,0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "gridSearchLR = GridSearchCV(modelLR, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearchLR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:\n",
      " {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n"
     ]
    }
   ],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', gridSearchLR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l1', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 50, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l1', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 100, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l1', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 150, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l1', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.0001, 'max_iter': 200, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l1', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 50, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l1', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 100, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l1', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 150, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l1', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.001, 'max_iter': 200, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l1', 'tol': 10}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 50, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l1', 'tol': 10}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l1', 'tol': 10}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 150, 'penalty': 'l2', 'tol': 10}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l1', 'tol': 10}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.610 (+/-0.001) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.01, 'max_iter': 200, 'penalty': 'l2', 'tol': 10}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.667 (+/-0.013) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.643 (+/-0.015) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l1', 'tol': 10}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.665 (+/-0.007) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.661 (+/-0.012) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 50, 'penalty': 'l2', 'tol': 10}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.665 (+/-0.015) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.656 (+/-0.003) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l1', 'tol': 10}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.665 (+/-0.007) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.661 (+/-0.012) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', 'tol': 10}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.668 (+/-0.012) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.667 (+/-0.014) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.657 (+/-0.030) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l1', 'tol': 10}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.665 (+/-0.007) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.661 (+/-0.012) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 150, 'penalty': 'l2', 'tol': 10}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.668 (+/-0.013) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.667 (+/-0.013) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.665 (+/-0.014) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.662 (+/-0.026) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l1', 'tol': 10}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.666 (+/-0.009) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.665 (+/-0.007) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.661 (+/-0.012) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 0.1, 'max_iter': 200, 'penalty': 'l2', 'tol': 10}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.719 (+/-0.022) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.711 (+/-0.017) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 50, 'penalty': 'l1', 'tol': 10}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.740 (+/-0.016) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.674 (+/-0.014) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 50, 'penalty': 'l2', 'tol': 10}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.718 (+/-0.022) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.710 (+/-0.011) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 100, 'penalty': 'l1', 'tol': 10}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.740 (+/-0.016) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.674 (+/-0.014) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'tol': 10}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.717 (+/-0.021) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.719 (+/-0.020) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.710 (+/-0.014) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 150, 'penalty': 'l1', 'tol': 10}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.740 (+/-0.016) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.674 (+/-0.014) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 150, 'penalty': 'l2', 'tol': 10}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.717 (+/-0.020) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.717 (+/-0.021) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.720 (+/-0.021) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.709 (+/-0.017) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 200, 'penalty': 'l1', 'tol': 10}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.754 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.740 (+/-0.016) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.674 (+/-0.014) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 1, 'max_iter': 200, 'penalty': 'l2', 'tol': 10}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.825 (+/-0.008) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.816 (+/-0.018) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.777 (+/-0.017) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 50, 'penalty': 'l1', 'tol': 10}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.820 (+/-0.012) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.792 (+/-0.026) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 50, 'penalty': 'l2', 'tol': 10}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.824 (+/-0.009) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.816 (+/-0.017) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.777 (+/-0.010) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 100, 'penalty': 'l1', 'tol': 10}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.820 (+/-0.012) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.792 (+/-0.026) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'tol': 10}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.824 (+/-0.009) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.815 (+/-0.013) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.784 (+/-0.027) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 150, 'penalty': 'l1', 'tol': 10}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.820 (+/-0.012) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.792 (+/-0.026) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 150, 'penalty': 'l2', 'tol': 10}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.826 (+/-0.008) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.824 (+/-0.009) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.820 (+/-0.010) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.775 (+/-0.016) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 200, 'penalty': 'l1', 'tol': 10}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.821 (+/-0.014) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.820 (+/-0.012) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.792 (+/-0.026) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 10, 'max_iter': 200, 'penalty': 'l2', 'tol': 10}\n",
      "0.803 (+/-0.007) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.803 (+/-0.007) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.801 (+/-0.005) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.794 (+/-0.011) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.791 (+/-0.010) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.762 (+/-0.015) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 50, 'penalty': 'l1', 'tol': 10}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.813 (+/-0.010) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.817 (+/-0.010) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.797 (+/-0.014) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 50, 'penalty': 'l2', 'tol': 10}\n",
      "0.803 (+/-0.007) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.803 (+/-0.008) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.801 (+/-0.006) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.795 (+/-0.008) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.790 (+/-0.012) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.761 (+/-0.013) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 100, 'penalty': 'l1', 'tol': 10}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.813 (+/-0.010) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.817 (+/-0.010) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.797 (+/-0.014) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 100, 'penalty': 'l2', 'tol': 10}\n",
      "0.803 (+/-0.008) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.803 (+/-0.007) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.801 (+/-0.006) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.793 (+/-0.010) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.789 (+/-0.012) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.760 (+/-0.020) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 150, 'penalty': 'l1', 'tol': 10}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.813 (+/-0.010) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.817 (+/-0.010) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.797 (+/-0.014) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 150, 'penalty': 'l2', 'tol': 10}\n",
      "0.803 (+/-0.007) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'tol': 1e-05}\n",
      "0.803 (+/-0.007) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.0001}\n",
      "0.801 (+/-0.006) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.001}\n",
      "0.794 (+/-0.009) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.01}\n",
      "0.788 (+/-0.016) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'tol': 0.1}\n",
      "0.767 (+/-0.013) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 200, 'penalty': 'l1', 'tol': 10}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'tol': 1e-05}\n",
      "0.813 (+/-0.012) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.0001}\n",
      "0.813 (+/-0.010) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.001}\n",
      "0.817 (+/-0.010) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.01}\n",
      "0.797 (+/-0.014) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'tol': 0.1}\n",
      "0.677 (+/-0.015) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'tol': 1}\n",
      "0.608 (+/-0.000) for {'C': 100, 'max_iter': 200, 'penalty': 'l2', 'tol': 10}\n"
     ]
    }
   ],
   "source": [
    "# All results\n",
    "means = gridSearchLR.cv_results_['mean_test_score']\n",
    "stds = gridSearchLR.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearchLR.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the results of the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3165,  497],\n",
       "       [ 306, 2033]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLR = LogisticRegression(C=10,max_iter=100,penalty='l1',tol=1e-05)\n",
    "modelLR.fit(x_train,y_train)\n",
    "y_pred = modelLR.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89      3662\n",
      "           1       0.80      0.87      0.84      2339\n",
      "\n",
      "    accuracy                           0.87      6001\n",
      "   macro avg       0.86      0.87      0.86      6001\n",
      "weighted avg       0.87      0.87      0.87      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(cv=5, random_state=0).fit(x_train, y_train)\n",
    "clf.predict(X[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KneighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier uses the k-nearest neighbors method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go for execution by default.(10h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelKNC = KNeighborsClassifier()\n",
    "modelKNC.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = modelKNC .predict(x_test)\n",
    "modelKNC .score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3453,  209],\n",
       "       [1661,  678]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.94      0.79      3662\n",
      "           1       0.76      0.29      0.42      2339\n",
      "\n",
      "    accuracy                           0.69      6001\n",
      "   macro avg       0.72      0.62      0.60      6001\n",
      "weighted avg       0.71      0.69      0.64      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again it's time to do magic and find the best hyperparameters. We will try to vary the algorithm parameter, n_neighbors and weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXECUTION D'ICI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKN = KNeighborsClassifier()\n",
    "parameter_space = {'algorithm': ['ball_tree','auto', 'kd_tree', 'brute'],\n",
    "                  'n_neighbors':[i for i in range(30,100,10)],\n",
    "                  'weights':['distance','uniform']}\n",
    "gridSearchKN = GridSearchCV(modelKN, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearchKN.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the best result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gridSearchKN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-192011940c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Best parameter set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best parameters found:\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridSearchKN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gridSearchKN' is not defined"
     ]
    }
   ],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', gridSearchKN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gridSearchKN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-a34758ee6ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# All results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridSearchKN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgridSearchKN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std_test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgridSearchKN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%0.3f (+/-%0.03f) for %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gridSearchKN' is not defined"
     ]
    }
   ],
   "source": [
    "# All results\n",
    "means = gridSearchKN.cv_results_['mean_test_score']\n",
    "stds = gridSearchKN.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearchKN.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the results of the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-26-2447c423a874>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-26-2447c423a874>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    modelKN = KNeighborsClassifier(A REMPLIR)\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "modelKN = KNeighborsClassifier(A REMPLIR)\n",
    "modelKN.fit(x_train,y_train)\n",
    "y_pred = modelKN.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6001, 4001]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c65aa5b361d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[1;32m   1850\u001b[0m     \"\"\"\n\u001b[1;32m   1851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1852\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1853\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/env/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 205\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6001, 4001]"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIN EXECUTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM algorithm finds the right hyperplans that differentiate classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2097,  332],\n",
       "       [ 204, 1368]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "conf_matrix_clf = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.86      0.89      2429\n",
      "          1       0.80      0.87      0.84      1572\n",
      "\n",
      "avg / total       0.87      0.87      0.87      4001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_clf = classification_report(y_test, y_pred)\n",
    "print(class_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
