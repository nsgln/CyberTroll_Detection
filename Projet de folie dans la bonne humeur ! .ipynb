{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PRE TREATMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing all our **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "## Actually uses\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "## Actually not uses \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from mpl_toolkits import mplot3d\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "DATA_PATH = os.path.join(\"./data\")\n",
    "DATA_NAME_CSV = \"CyberTroll.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of our data and transformation into DataFrame with **pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the .csv file into a DataFrame\n",
    "def load_data(data_path=DATA_PATH,data_name_csv=DATA_NAME_CSV):\n",
    "        # Path to file mushrooms.csv\n",
    "        csv_path = os.path.join(data_path,data_name_csv)\n",
    "        # Object DATA_FRAME\n",
    "        return pd.read_csv(csv_path)\n",
    "\n",
    "# execution\n",
    "data_frame = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what this data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation/notes</th>\n",
       "      <th>annotation/label/0</th>\n",
       "      <th>extras</th>\n",
       "      <th>metadata/first_done_at</th>\n",
       "      <th>metadata/last_updated_at</th>\n",
       "      <th>metadata/sec_taken</th>\n",
       "      <th>metadata/last_updated_by</th>\n",
       "      <th>metadata/status</th>\n",
       "      <th>metadata/evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>She is as dirty as they come  and that crook R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>why did you fuck it up. I could do it all day ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dude they dont finish enclosing the fucking sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WTF are you talking about Men? No men thats no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  annotation/notes  \\\n",
       "0                             Get fucking real dude.               NaN   \n",
       "1  She is as dirty as they come  and that crook R...               NaN   \n",
       "2  why did you fuck it up. I could do it all day ...               NaN   \n",
       "3  Dude they dont finish enclosing the fucking sh...               NaN   \n",
       "4  WTF are you talking about Men? No men thats no...               NaN   \n",
       "\n",
       "   annotation/label/0  extras  metadata/first_done_at  \\\n",
       "0                   1     NaN           1527503426000   \n",
       "1                   1     NaN           1527503426000   \n",
       "2                   1     NaN           1527503426000   \n",
       "3                   1     NaN           1527503426000   \n",
       "4                   1     NaN           1527503426000   \n",
       "\n",
       "   metadata/last_updated_at  metadata/sec_taken      metadata/last_updated_by  \\\n",
       "0             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "1             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "2             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "3             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "4             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "\n",
       "  metadata/status metadata/evaluation  \n",
       "0            done                NONE  \n",
       "1            done                NONE  \n",
       "2            done                NONE  \n",
       "3            done                NONE  \n",
       "4            done                NONE  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check of the quantity of samples and the diversity of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation/notes</th>\n",
       "      <th>annotation/label/0</th>\n",
       "      <th>extras</th>\n",
       "      <th>metadata/first_done_at</th>\n",
       "      <th>metadata/last_updated_at</th>\n",
       "      <th>metadata/sec_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20001.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000100e+04</td>\n",
       "      <td>2.000100e+04</td>\n",
       "      <td>20001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.717817e+04</td>\n",
       "      <td>2.717817e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527504e+12</td>\n",
       "      <td>1.527504e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotation/notes  annotation/label/0  extras  metadata/first_done_at  \\\n",
       "count               0.0        20001.000000     0.0            2.000100e+04   \n",
       "mean                NaN            0.391080     NaN            1.527503e+12   \n",
       "std                 NaN            0.488005     NaN            2.717817e+04   \n",
       "min                 NaN            0.000000     NaN            1.527503e+12   \n",
       "25%                 NaN            0.000000     NaN            1.527503e+12   \n",
       "50%                 NaN            0.000000     NaN            1.527503e+12   \n",
       "75%                 NaN            1.000000     NaN            1.527503e+12   \n",
       "max                 NaN            1.000000     NaN            1.527504e+12   \n",
       "\n",
       "       metadata/last_updated_at  metadata/sec_taken  \n",
       "count              2.000100e+04             20001.0  \n",
       "mean               1.527503e+12                 0.0  \n",
       "std                2.717817e+04                 0.0  \n",
       "min                1.527503e+12                 0.0  \n",
       "25%                1.527503e+12                 0.0  \n",
       "50%                1.527503e+12                 0.0  \n",
       "75%                1.527503e+12                 0.0  \n",
       "max                1.527504e+12                 0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is a null value and all the indexes we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content                         0\n",
       "annotation/notes            20001\n",
       "annotation/label/0              0\n",
       "extras                      20001\n",
       "metadata/first_done_at          0\n",
       "metadata/last_updated_at        0\n",
       "metadata/sec_taken              0\n",
       "metadata/last_updated_by        0\n",
       "metadata/status                 0\n",
       "metadata/evaluation             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**annotation/notes**,**extras** is composed of null values so its implication in a classification algorithm is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['annotation/notes','extras'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at all the unique choices we have in all indexes, if there is an index that always has the same value we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content : ['Get fucking real dude.'\n",
      " \"She is as dirty as they come  and that crook Rengel  the Dems are so fucking corrupt it's a joke. Make Republicans look like  ...\"\n",
      " \"why did you fuck it up. I could do it all day too. Let's do it when you have an hour. Ping me later to sched writing a book here.\"\n",
      " ... 'hahahahaha >:) im evil mwahahahahahahahahaha'\n",
      " 'What&;s something unique about Ohio? :)'\n",
      " 'Who is the biggest gossiper you know?']\n",
      "annotation/label/0 : [1 0]\n",
      "metadata/first_done_at : [1527503426000 1527503427000 1527503428000 1527503429000 1527503430000\n",
      " 1527503431000 1527503432000 1527503433000 1527503434000 1527503435000\n",
      " 1527503436000 1527503437000 1527503438000 1527503439000 1527503440000\n",
      " 1527503441000 1527503442000 1527503443000 1527503444000 1527503445000\n",
      " 1527503446000 1527503447000 1527503448000 1527503449000 1527503450000\n",
      " 1527503451000 1527503452000 1527503453000 1527503454000 1527503455000\n",
      " 1527503456000 1527503457000 1527503458000 1527503459000 1527503460000\n",
      " 1527503461000 1527503462000 1527503463000 1527503464000 1527503465000\n",
      " 1527503466000 1527503467000 1527503468000 1527503469000 1527503470000\n",
      " 1527503471000 1527503472000 1527503473000 1527503474000 1527503475000\n",
      " 1527503476000 1527503477000 1527503478000 1527503479000 1527503480000\n",
      " 1527503481000 1527503482000 1527503483000 1527503484000 1527503485000\n",
      " 1527503486000 1527503487000 1527503488000 1527503489000 1527503490000\n",
      " 1527503491000 1527503492000 1527503493000 1527503494000 1527503495000\n",
      " 1527503496000 1527503497000 1527503498000 1527503499000 1527503500000\n",
      " 1527503501000 1527503502000 1527503503000 1527503504000 1527503505000\n",
      " 1527503506000 1527503507000 1527503508000 1527503509000 1527503510000\n",
      " 1527503511000 1527503512000 1527503513000 1527503514000 1527503515000\n",
      " 1527503516000 1527503517000 1527503518000 1527503519000]\n",
      "metadata/last_updated_at : [1527503426000 1527503427000 1527503428000 1527503429000 1527503430000\n",
      " 1527503431000 1527503432000 1527503433000 1527503434000 1527503435000\n",
      " 1527503436000 1527503437000 1527503438000 1527503439000 1527503440000\n",
      " 1527503441000 1527503442000 1527503443000 1527503444000 1527503445000\n",
      " 1527503446000 1527503447000 1527503448000 1527503449000 1527503450000\n",
      " 1527503451000 1527503452000 1527503453000 1527503454000 1527503455000\n",
      " 1527503456000 1527503457000 1527503458000 1527503459000 1527503460000\n",
      " 1527503461000 1527503462000 1527503463000 1527503464000 1527503465000\n",
      " 1527503466000 1527503467000 1527503468000 1527503469000 1527503470000\n",
      " 1527503471000 1527503472000 1527503473000 1527503474000 1527503475000\n",
      " 1527503476000 1527503477000 1527503478000 1527503479000 1527503480000\n",
      " 1527503481000 1527503482000 1527503483000 1527503484000 1527503485000\n",
      " 1527503486000 1527503487000 1527503488000 1527503489000 1527503490000\n",
      " 1527503491000 1527503492000 1527503493000 1527503494000 1527503495000\n",
      " 1527503496000 1527503497000 1527503498000 1527503499000 1527503500000\n",
      " 1527503501000 1527503502000 1527503503000 1527503504000 1527503505000\n",
      " 1527503506000 1527503507000 1527503508000 1527503509000 1527503510000\n",
      " 1527503511000 1527503512000 1527503513000 1527503514000 1527503515000\n",
      " 1527503516000 1527503517000 1527503518000 1527503519000]\n",
      "metadata/sec_taken : [0]\n",
      "metadata/last_updated_by : ['jI67aE5hwwdh6l16bcfFVnpyREd2']\n",
      "metadata/status : ['done']\n",
      "metadata/evaluation : ['NONE']\n"
     ]
    }
   ],
   "source": [
    "for index in data_frame.columns:\n",
    "        print(str(index) + \" : \" + str(data_frame[index].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata/sec_taken**,**metadata/last_updated_by**,**metadata/status**,**metadata/evaluation** is composed of a single variable so its implication in a classification algorithm is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['metadata/sec_taken','metadata/last_updated_by','metadata/status','metadata/evaluation'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata/last_updated_at**,**metadata/first_done_at** is composed of timestamp so it's implication in not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['metadata/last_updated_at','metadata/first_done_at'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation/label/0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>She is as dirty as they come  and that crook R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>why did you fuck it up. I could do it all day ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dude they dont finish enclosing the fucking sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WTF are you talking about Men? No men thats no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  annotation/label/0\n",
       "0                             Get fucking real dude.                   1\n",
       "1  She is as dirty as they come  and that crook R...                   1\n",
       "2  why did you fuck it up. I could do it all day ...                   1\n",
       "3  Dude they dont finish enclosing the fucking sh...                   1\n",
       "4  WTF are you talking about Men? No men thats no...                   1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns for easier use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.rename(columns={\"content\" : \"sentence\",\"annotation/label/0\" :\"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text may contain numbers, special characters, and unwanted spaces. We will remove all the special characters, numbers, and unwanted spaces from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer \n",
    "stemmer = WordNetLemmatizer()\n",
    "# Function to apply on our sentence\n",
    "def converterSentence(text):\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # remove all single characters\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # Converting to Lowercase\n",
    "    text = text.lower()\n",
    "    # Lemmatization\n",
    "    text = text.split()\n",
    "    text = [stemmer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    get fucking real dude\n",
       "1        she is a dirty a they come and that crook reng...\n",
       "2        why did you fuck it up could do it all day too...\n",
       "3        dude they dont finish enclosing the fucking sh...\n",
       "4        wtf are you talking about men no men thats not...\n",
       "                               ...                        \n",
       "19996    dont but what is complaining about it going to do\n",
       "19997    bahah yeah totally just gonna get pissed at yo...\n",
       "19998             hahahahaha im evil mwahahahahahahahahaha\n",
       "19999                     what something unique about ohio\n",
       "20000                 who is the biggest gossiper you know\n",
       "Name: sentence, Length: 20001, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['sentence']= data_frame.sentence.apply(converterSentence)\n",
    "data_frame.sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different approaches exist to convert text into the corresponding numerical form. But we are going to use Bag of Words Model because it is the most efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default Vectorizer & Default model to have a first overview of the result** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data_frame.sentence)\n",
    "Y = data_frame.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag of words approach works fine for converting text to numbers. However, it has one drawback. It assigns a score to a word based on its occurrence in a particular document. It doesn't take into account the fact that the word might also be having a high frequency of occurrence in other documents as well. TFIDF resolves this issue by multiplying the term frequency of a word by the inverse document frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "classifier.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2429\n",
      "           1       0.87      0.93      0.90      1572\n",
      "\n",
      "    accuracy                           0.92      4001\n",
      "   macro avg       0.91      0.92      0.92      4001\n",
      "weighted avg       0.92      0.92      0.92      4001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_rdtree = classifier.predict(x_test)\n",
    "print(classification_report(y_test,y_pred_rdtree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We obtain the following confusion matrix : \n",
      " [[2216  213]\n",
      " [ 103 1469]]\n"
     ]
    }
   ],
   "source": [
    "confusion_rdtree = confusion_matrix(y_test, y_pred_rdtree)\n",
    "print(\"We obtain the following confusion matrix : \\n\", confusion_rdtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're using RandomizedSearchCV in order to optimize by cross-validated search the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 24.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 100,\n",
       " 'min_samples_split': 10,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_depth': 30}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best estimator : the best hyperparameters\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [100, 300, 500, 800, 1200]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5, 8, 15, 25, 30]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10, 15, 100]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 5, 10] \n",
    "\n",
    "random_grid = dict(n_estimators = n_estimators, \n",
    "              max_depth = max_depth,  \n",
    "              min_samples_split = min_samples_split, \n",
    "              min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
    "                               param_distributions = random_grid, \n",
    "                               n_iter = 100, \n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1)\n",
    "rf_random.fit(x_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to  plot the validation curve to find the best value for the n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_scores, test_scores = validation_curve(\n",
    "#                                 RandomForestClassifier(),\n",
    "#                                 X = x_train, y = y_train, \n",
    "#                                 param_name = 'n_estimators', \n",
    "#                                 param_range = [100, 300, 500, 750, 800, 1200], cv = 3)\n",
    "\n",
    "# param_range = np.logspace(-6, -1, 5)\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "# plt.title(\"Validation Curve for Random Forest\")\n",
    "# plt.xlabel(\"Values of Hyperparameter n_estimators\")\n",
    "# plt.ylabel(\"Accuracy Score\")\n",
    "\n",
    "# plt.plot(param_range, train_scores_mean, label=\"Training scores\")\n",
    "# plt.plot(param_range, test_scores_mean, label=\"Cross-Validation Score\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt to find parameters for the vectorizer which could impact the model. But the sentences being too small the min_df and max_df parameters are useless here. We still just tried to vary the number of features but that did not affect the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_MIN_DEF= [x/100 for x in range(1,50,5)]\n",
    "LIST_MAX_DEF= [x for x in range(90,100)]\n",
    "LIST_MAX_DEF.reverse()\n",
    "LIST_MAX_FEATURES = [x for x in range(100,2000,50)]\n",
    "def customVectorizer(listMinDef=LIST_MIN_DEF,listMaxDef=LIST_MAX_DEF,listMaxFeatures=LIST_MAX_FEATURES):\n",
    "    listVectorizer = []\n",
    "    for maxFeatures in listMaxFeatures:\n",
    "        listVectorizer.append(CountVectorizer(stop_words='english',max_features=maxFeatures))  \n",
    "    return listVectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the result of this function in a file located in the data folder, just for information there is just marked the same for each variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vary vectorizer parameters to see if it impacts the default Random Forest model\n",
    "def ImpactOfVectorizer():\n",
    "    fichier = open(\"data/dataRFCDefaultCustomVectorizer.txt\", \"a\")\n",
    "    for vecto in customVectorizer():\n",
    "        vectorizer = vecto\n",
    "        X = vectorizer.fit_transform(data_frame.sentence)\n",
    "        Y = data_frame.label\n",
    "        tfidfconverter = TfidfTransformer()\n",
    "        X = tfidfconverter.fit_transform(X)\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "        # Simple Random Forest Classifier\n",
    "        classifier = RandomForestClassifier(n_estimators=10, random_state=0)\n",
    "        classifier.fit(x_train, y_train) \n",
    "        crboost = classification_report(y_test,y_pred,digits=10,output_dict=True)\n",
    "        fichier.write(str(crboost['0']['precision'])+\" \" +str(crboost['1']['precision'])+\"\\n\")\n",
    "    fichier.close()\n",
    "# The famous line that saves you 5 s               \n",
    "# ImpactOfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result :\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> 0.9555843035791289 0.8733650416171225\n",
    "<br/> ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The answer to the question “What machine learning model should I use?” is always “It depends.” Even the most experienced data scientists can’t tell which algorithm will perform best before experimenting them.\"\n",
    "\n",
    "In order to find the optimum model, we tried to make as many models as possible to know which would be the best. Here are the 6 models that were made.\n",
    "\n",
    "MLPClassifier, DecisionTreeClassifier, RandomForestClassifier, KNeighborsClassifier, LogisticRegression and finally SVM (Support Vector Machine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use these trains and tests for all our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data_frame.sentence)\n",
    "Y = data_frame.label\n",
    "# TFID\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)\n",
    "# SPLIT\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model aims to optimize the log-loss function using LBGFGS or stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the default neural network (45 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\singl\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelMLP = MLPClassifier()\n",
    "modelMLP.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the trained network to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = modelMLP.predict(x_test)\n",
    "modelMLP.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2911,  751],\n",
       "       [ 183, 2156]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.79      0.86      3662\n",
      "           1       0.74      0.92      0.82      2339\n",
      "\n",
      "    accuracy                           0.84      6001\n",
      "   macro avg       0.84      0.86      0.84      6001\n",
      "weighted avg       0.86      0.84      0.85      6001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to find more optimal parameters, with the magic GridSearchCV multi-threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelMLP = MLPClassifier()\n",
    "parameter_space = {'activation': ['logistic','tanh', 'relu'],\n",
    "                  'hidden_layer_sizes':[i for i in range(1,220,20)],\n",
    "                  'alpha':[0.0001,0.001,0.01,0.1,1],\n",
    "                  'max_iter':[50, 100, 150, 200]}\n",
    "gridSearch = GridSearchCV(modelMLP, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearch.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameters set\n",
    "print('Best parameters found:\\n', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All results\n",
    "means = gridSearch.cv_results_['mean_test_score']\n",
    "stds = gridSearch.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearch.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to improve the performances of this classifier, we will look at how accuracy evolves when we change the size of the test set, the number of hidden layer of the classifier or the number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, the function to change the size of the test set.\n",
    "def calculate_test_size(X, y, o):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=o)\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(X_train)\n",
    "\n",
    "\tscaler.transform(X_train)\n",
    "\tscaler.transform(X_test)\n",
    "\tmlp= MLPClassifier(hidden_layer_sizes=(3, 13), max_iter=500)\n",
    "\tmlp.fit(X_train, y_train.ravel())\n",
    "\tpredictions = mlp.predict(X_test)\n",
    "\n",
    "\treturn accuracy_score(y_test, predictions)\n",
    "\n",
    "#Next, the function to change the number of the hidden layer.\n",
    "def calculate_hidden(X, y, o):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33)\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(X_train)\n",
    "\n",
    "\tscaler.transform(X_train)\n",
    "\tscaler.transform(X_test)\n",
    "\tmlp= MLPClassifier(hidden_layer_sizes=(3, o), max_iter=500)\n",
    "\tmlp.fit(X_train, y_train.ravel())\n",
    "\tpredictions = m\n",
    "    lp.predict(X_test)\n",
    "\n",
    "\treturn accuracy_score(y_test, predictions)\n",
    "\n",
    "#Finally, the function to change the number of iteration.\n",
    "def calculate_it(X, y, o):\n",
    "\tX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.33)\n",
    "\tscaler = StandardScaler()\n",
    "\tscaler.fit(X_train)\n",
    "\n",
    "\tscaler.transform(X_train)\n",
    "\tscaler.transform(X_test)\n",
    "\tmlp= MLPClassifier(hidden_layer_sizes=(3, 13), max_iter=o)\n",
    "\tmlp.fit(X_train, y_train.ravel())\n",
    "\tpredictions = mlp.predict(X_test)\n",
    "\n",
    "\treturn accuracy_score(y_test, predictions)\n",
    "\n",
    "test_size = np.arange(0.1, 1, .1)\n",
    "size_o_test = [calculate_test_size(X, Y, i) for i in test_size]\n",
    "\n",
    "hidden_test = np.arange(5, 50, 5)\n",
    "hidd_of_test = [calculate_hidden(X, Y, i) for i in hidden_test]\n",
    "\n",
    "it_test = np.arange(100, 1000, 50)\n",
    "it_of_test = [calculate_it(X, Y, i) for i in it_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the purpose to visualize its results, we are now going to display them in a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(test_size, size_o_test)\n",
    "plt.title(\"Experimentation on test size\")\n",
    "plt.xlabel(\"Size of test set\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(hidden_test, hidd_of_test)\n",
    "plt.title(\"Experimentation on number of hidden layers\")\n",
    "plt.xlabel(\"Number of hidden layer\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(it_test, it_of_test)\n",
    "plt.title(\"Experimentation on number of iteration\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classification is used in statistics to model the probability of a certain class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with the default one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR = LogisticRegression()\n",
    "modelLR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelLR.predict(x_test)\n",
    "modelLR.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to add hyperparameter to get a better accuracy.\n",
    "\n",
    "For this one, 4 hyperparameters : C, penality, max_iter and tol.(10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR = LogisticRegression()\n",
    "parameter_space = {'penalty': ['l1','l2'],\n",
    "                  'C':[0.0001, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "                  'max_iter':[50, 100, 150, 200],\n",
    "                  'tol':[0.00001,0.0001, 0.001, 0.01, 0.1, 1, 10]}\n",
    "gridSearchLR = GridSearchCV(modelLR, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearchLR.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the best results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', gridSearchLR.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All results\n",
    "means = gridSearchLR.cv_results_['mean_test_score']\n",
    "stds = gridSearchLR.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearchLR.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the results of the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR = LogisticRegression(C=10,max_iter=100,penalty='l1',tol=1e-05)\n",
    "modelLR.fit(x_train,y_train)\n",
    "y_pred = modelLR.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionCV(cv=5, random_state=0).fit(x_train, y_train)\n",
    "clf.predict(X[:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KneighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classifier uses the k-nearest neighbors method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go for execution by default.(10h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKNC = KNeighborsClassifier()\n",
    "modelKNC.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = modelKNC .predict(x_test)\n",
    "modelKNC .score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again it's time to do magic and find the best hyperparameters. We will try to vary the algorithm parameter, n_neighbors and weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXECUTION D'ICI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKN = KNeighborsClassifier()\n",
    "parameter_space = {'algorithm': ['ball_tree','auto', 'kd_tree', 'brute'],\n",
    "                  'n_neighbors':[i for i in range(30,100,10)],\n",
    "                  'weights':['distance','uniform']}\n",
    "gridSearchKN = GridSearchCV(modelKN, parameter_space, n_jobs=-1, cv=3)\n",
    "gridSearchKN.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the best result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best parameter set\n",
    "print('Best parameters found:\\n', gridSearchKN.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All results\n",
    "means = gridSearchKN.cv_results_['mean_test_score']\n",
    "stds = gridSearchKN.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, gridSearchKN.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a closer look at the results of the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelKN = KNeighborsClassifier(A REMPLIR)\n",
    "modelKN.fit(x_train,y_train)\n",
    "y_pred = modelKN.predict(x_test)\n",
    "conf_matrix = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr = classification_report(y_test,y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIN EXECUTION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM algorithm finds the right hyperplans that differentiate classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "conf_matrix_clf = confusion_matrix(y_test,y_pred)\n",
    "conf_matrix_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(x_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_clf = classification_report(y_test, y_pred)\n",
    "print(class_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
