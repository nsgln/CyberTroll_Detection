{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PRE TREATMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing all our **Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT\n",
    "## Actually uses\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "## Actually not uses \n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "from itertools import combinations\n",
    "from itertools import chain\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATHS\n",
    "DATA_PATH = os.path.join(\"./data\")\n",
    "DATA_NAME_CSV = \"CyberTroll.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraction of our data and transformation into DataFrame with **pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming the .csv file into a DataFrame\n",
    "def load_data(data_path=DATA_PATH,data_name_csv=DATA_NAME_CSV):\n",
    "        # Path to file mushrooms.csv\n",
    "        csv_path = os.path.join(data_path,data_name_csv)\n",
    "        # Object DATA_FRAME\n",
    "        return pd.read_csv(csv_path)\n",
    "\n",
    "# execution\n",
    "data_frame = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what this data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation/notes</th>\n",
       "      <th>annotation/label/0</th>\n",
       "      <th>extras</th>\n",
       "      <th>metadata/first_done_at</th>\n",
       "      <th>metadata/last_updated_at</th>\n",
       "      <th>metadata/sec_taken</th>\n",
       "      <th>metadata/last_updated_by</th>\n",
       "      <th>metadata/status</th>\n",
       "      <th>metadata/evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>She is as dirty as they come  and that crook R...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>why did you fuck it up. I could do it all day ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dude they dont finish enclosing the fucking sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WTF are you talking about Men? No men thats no...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>1527503426000</td>\n",
       "      <td>0</td>\n",
       "      <td>jI67aE5hwwdh6l16bcfFVnpyREd2</td>\n",
       "      <td>done</td>\n",
       "      <td>NONE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  annotation/notes  \\\n",
       "0                             Get fucking real dude.               NaN   \n",
       "1  She is as dirty as they come  and that crook R...               NaN   \n",
       "2  why did you fuck it up. I could do it all day ...               NaN   \n",
       "3  Dude they dont finish enclosing the fucking sh...               NaN   \n",
       "4  WTF are you talking about Men? No men thats no...               NaN   \n",
       "\n",
       "   annotation/label/0  extras  metadata/first_done_at  \\\n",
       "0                   1     NaN           1527503426000   \n",
       "1                   1     NaN           1527503426000   \n",
       "2                   1     NaN           1527503426000   \n",
       "3                   1     NaN           1527503426000   \n",
       "4                   1     NaN           1527503426000   \n",
       "\n",
       "   metadata/last_updated_at  metadata/sec_taken      metadata/last_updated_by  \\\n",
       "0             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "1             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "2             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "3             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "4             1527503426000                   0  jI67aE5hwwdh6l16bcfFVnpyREd2   \n",
       "\n",
       "  metadata/status metadata/evaluation  \n",
       "0            done                NONE  \n",
       "1            done                NONE  \n",
       "2            done                NONE  \n",
       "3            done                NONE  \n",
       "4            done                NONE  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check of the quantity of samples and the diversity of cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation/notes</th>\n",
       "      <th>annotation/label/0</th>\n",
       "      <th>extras</th>\n",
       "      <th>metadata/first_done_at</th>\n",
       "      <th>metadata/last_updated_at</th>\n",
       "      <th>metadata/sec_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20001.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000100e+04</td>\n",
       "      <td>2.000100e+04</td>\n",
       "      <td>20001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.391080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.717817e+04</td>\n",
       "      <td>2.717817e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>1.527503e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.527504e+12</td>\n",
       "      <td>1.527504e+12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       annotation/notes  annotation/label/0  extras  metadata/first_done_at  \\\n",
       "count               0.0        20001.000000     0.0            2.000100e+04   \n",
       "mean                NaN            0.391080     NaN            1.527503e+12   \n",
       "std                 NaN            0.488005     NaN            2.717817e+04   \n",
       "min                 NaN            0.000000     NaN            1.527503e+12   \n",
       "25%                 NaN            0.000000     NaN            1.527503e+12   \n",
       "50%                 NaN            0.000000     NaN            1.527503e+12   \n",
       "75%                 NaN            1.000000     NaN            1.527503e+12   \n",
       "max                 NaN            1.000000     NaN            1.527504e+12   \n",
       "\n",
       "       metadata/last_updated_at  metadata/sec_taken  \n",
       "count              2.000100e+04             20001.0  \n",
       "mean               1.527503e+12                 0.0  \n",
       "std                2.717817e+04                 0.0  \n",
       "min                1.527503e+12                 0.0  \n",
       "25%                1.527503e+12                 0.0  \n",
       "50%                1.527503e+12                 0.0  \n",
       "75%                1.527503e+12                 0.0  \n",
       "max                1.527504e+12                 0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if there is a null value and all the indexes we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content                         0\n",
       "annotation/notes            20001\n",
       "annotation/label/0              0\n",
       "extras                      20001\n",
       "metadata/first_done_at          0\n",
       "metadata/last_updated_at        0\n",
       "metadata/sec_taken              0\n",
       "metadata/last_updated_by        0\n",
       "metadata/status                 0\n",
       "metadata/evaluation             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**annotation/notes**,**extras** is composed of null values so its implication in a classification algorithm is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['annotation/notes','extras'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at all the unique choices we have in all indexes, if there is an index that always has the same value we can remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content : ['Get fucking real dude.'\n",
      " \"She is as dirty as they come  and that crook Rengel  the Dems are so fucking corrupt it's a joke. Make Republicans look like  ...\"\n",
      " \"why did you fuck it up. I could do it all day too. Let's do it when you have an hour. Ping me later to sched writing a book here.\"\n",
      " ... 'hahahahaha >:) im evil mwahahahahahahahahaha'\n",
      " 'What&;s something unique about Ohio? :)'\n",
      " 'Who is the biggest gossiper you know?']\n",
      "annotation/label/0 : [1 0]\n",
      "metadata/first_done_at : [1527503426000 1527503427000 1527503428000 1527503429000 1527503430000\n",
      " 1527503431000 1527503432000 1527503433000 1527503434000 1527503435000\n",
      " 1527503436000 1527503437000 1527503438000 1527503439000 1527503440000\n",
      " 1527503441000 1527503442000 1527503443000 1527503444000 1527503445000\n",
      " 1527503446000 1527503447000 1527503448000 1527503449000 1527503450000\n",
      " 1527503451000 1527503452000 1527503453000 1527503454000 1527503455000\n",
      " 1527503456000 1527503457000 1527503458000 1527503459000 1527503460000\n",
      " 1527503461000 1527503462000 1527503463000 1527503464000 1527503465000\n",
      " 1527503466000 1527503467000 1527503468000 1527503469000 1527503470000\n",
      " 1527503471000 1527503472000 1527503473000 1527503474000 1527503475000\n",
      " 1527503476000 1527503477000 1527503478000 1527503479000 1527503480000\n",
      " 1527503481000 1527503482000 1527503483000 1527503484000 1527503485000\n",
      " 1527503486000 1527503487000 1527503488000 1527503489000 1527503490000\n",
      " 1527503491000 1527503492000 1527503493000 1527503494000 1527503495000\n",
      " 1527503496000 1527503497000 1527503498000 1527503499000 1527503500000\n",
      " 1527503501000 1527503502000 1527503503000 1527503504000 1527503505000\n",
      " 1527503506000 1527503507000 1527503508000 1527503509000 1527503510000\n",
      " 1527503511000 1527503512000 1527503513000 1527503514000 1527503515000\n",
      " 1527503516000 1527503517000 1527503518000 1527503519000]\n",
      "metadata/last_updated_at : [1527503426000 1527503427000 1527503428000 1527503429000 1527503430000\n",
      " 1527503431000 1527503432000 1527503433000 1527503434000 1527503435000\n",
      " 1527503436000 1527503437000 1527503438000 1527503439000 1527503440000\n",
      " 1527503441000 1527503442000 1527503443000 1527503444000 1527503445000\n",
      " 1527503446000 1527503447000 1527503448000 1527503449000 1527503450000\n",
      " 1527503451000 1527503452000 1527503453000 1527503454000 1527503455000\n",
      " 1527503456000 1527503457000 1527503458000 1527503459000 1527503460000\n",
      " 1527503461000 1527503462000 1527503463000 1527503464000 1527503465000\n",
      " 1527503466000 1527503467000 1527503468000 1527503469000 1527503470000\n",
      " 1527503471000 1527503472000 1527503473000 1527503474000 1527503475000\n",
      " 1527503476000 1527503477000 1527503478000 1527503479000 1527503480000\n",
      " 1527503481000 1527503482000 1527503483000 1527503484000 1527503485000\n",
      " 1527503486000 1527503487000 1527503488000 1527503489000 1527503490000\n",
      " 1527503491000 1527503492000 1527503493000 1527503494000 1527503495000\n",
      " 1527503496000 1527503497000 1527503498000 1527503499000 1527503500000\n",
      " 1527503501000 1527503502000 1527503503000 1527503504000 1527503505000\n",
      " 1527503506000 1527503507000 1527503508000 1527503509000 1527503510000\n",
      " 1527503511000 1527503512000 1527503513000 1527503514000 1527503515000\n",
      " 1527503516000 1527503517000 1527503518000 1527503519000]\n",
      "metadata/sec_taken : [0]\n",
      "metadata/last_updated_by : ['jI67aE5hwwdh6l16bcfFVnpyREd2']\n",
      "metadata/status : ['done']\n",
      "metadata/evaluation : ['NONE']\n"
     ]
    }
   ],
   "source": [
    "for index in data_frame.columns:\n",
    "        print(str(index) + \" : \" + str(data_frame[index].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata/sec_taken**,**metadata/last_updated_by**,**metadata/status**,**metadata/evaluation** is composed of a single variable so its implication in a classification algorithm is not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['metadata/sec_taken','metadata/last_updated_by','metadata/status','metadata/evaluation'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**metadata/last_updated_at**,**metadata/first_done_at** is composed of timestamp so it's implication in not relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.drop(['metadata/last_updated_at','metadata/first_done_at'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>annotation/label/0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Get fucking real dude.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>She is as dirty as they come  and that crook R...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>why did you fuck it up. I could do it all day ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Dude they dont finish enclosing the fucking sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>WTF are you talking about Men? No men thats no...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  annotation/label/0\n",
       "0                             Get fucking real dude.                   1\n",
       "1  She is as dirty as they come  and that crook R...                   1\n",
       "2  why did you fuck it up. I could do it all day ...                   1\n",
       "3  Dude they dont finish enclosing the fucking sh...                   1\n",
       "4  WTF are you talking about Men? No men thats no...                   1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns for easier use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = data_frame.rename(columns={\"content\" : \"sentence\",\"annotation/label/0\" :\"label\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text may contain numbers, special characters, and unwanted spaces. We will remove all the special characters, numbers, and unwanted spaces from our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer \n",
    "stemmer = WordNetLemmatizer()\n",
    "# Function to apply on our sentence\n",
    "def converterSentence(text):\n",
    "    # Remove all the special characters\n",
    "    text = re.sub(r'\\W', ' ', text)\n",
    "    # remove all single characters\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', ' ', text)\n",
    "    # Substituting multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "    # Converting to Lowercase\n",
    "    text = text.lower()\n",
    "    # Lemmatization\n",
    "    text = text.split()\n",
    "    text = [stemmer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                    get fucking real dude\n",
       "1        she is a dirty a they come and that crook reng...\n",
       "2        why did you fuck it up could do it all day too...\n",
       "3        dude they dont finish enclosing the fucking sh...\n",
       "4        wtf are you talking about men no men thats not...\n",
       "                               ...                        \n",
       "19996    dont but what is complaining about it going to do\n",
       "19997    bahah yeah totally just gonna get pissed at yo...\n",
       "19998             hahahahaha im evil mwahahahahahahahahaha\n",
       "19999                     what something unique about ohio\n",
       "20000                 who is the biggest gossiper you know\n",
       "Name: sentence, Length: 20001, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame['sentence']= data_frame.sentence.apply(converterSentence)\n",
    "data_frame.sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different approaches exist to convert text into the corresponding numerical form. But we are going to use Bag of Words Model because it is the most efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Default Vectorizer** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(data_frame.sentence)\n",
    "Y = data_frame.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bag of words approach works fine for converting text to numbers. However, it has one drawback. It assigns a score to a word based on its occurrence in a particular document. It doesn't take into account the fact that the word might also be having a high frequency of occurrence in other documents as well. TFIDF resolves this issue by multiplying the term frequency of a word by the inverse document frequency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Random Forest Classifier\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)\n",
    "classifier.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      2429\n",
      "           1       0.87      0.93      0.90      1572\n",
      "\n",
      "    accuracy                           0.92      4001\n",
      "   macro avg       0.91      0.92      0.92      4001\n",
      "weighted avg       0.92      0.92      0.92      4001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(x_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
